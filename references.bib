
@article{shridhar_comprehensive_2019,
	title = {A {Comprehensive} guide to {Bayesian} {Convolutional} {Neural} {Network} with {Variational} {Inference}},
	url = {http://arxiv.org/abs/1901.02731},
	abstract = {Artificial Neural Networks are connectionist systems that perform a given task by learning on examples without having prior knowledge about the task. This is done by finding an optimal point estimate for the weights in every node. Generally, the network using point estimates as weights perform well with large datasets, but they fail to express uncertainty in regions with little or no data, leading to overconfident decisions. In this paper, Bayesian Convolutional Neural Network (BayesCNN) using Variational Inference is proposed, that introduces probability distribution over the weights. Furthermore, the proposed BayesCNN architecture is applied to tasks like Image Classification, Image Super-Resolution and Generative Adversarial Networks. The results are compared to point-estimates based architectures on MNIST, CIFAR-10 and CIFAR-100 datasets for Image CLassification task, on BSD300 dataset for Image Super Resolution task and on CIFAR10 dataset again for Generative Adversarial Network task. BayesCNN is based on Bayes by Backprop which derives a variational approximation to the true posterior. We, therefore, introduce the idea of applying two convolutional operations, one for the mean and one for the variance. Our proposed method not only achieves performances equivalent to frequentist inference in identical architectures but also incorporate a measurement for uncertainties and regularisation. It further eliminates the use of dropout in the model. Moreover, we predict how certain the model prediction is based on the epistemic and aleatoric uncertainties and empirically show how the uncertainty can decrease, allowing the decisions made by the network to become more deterministic as the training accuracy increases. Finally, we propose ways to prune the Bayesian architecture and to make it more computational and time effective.},
	urldate = {2022-03-18},
	journal = {arXiv:1901.02731 [cs, stat]},
	author = {Shridhar, Kumar and Laumann, Felix and Liwicki, Marcus},
	month = jan,
	year = {2019},
	note = {arXiv: 1901.02731},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:/home/harnist/Zotero/storage/LS296KMN/Shridhar et al. - 2019 - A Comprehensive guide to Bayesian Convolutional Ne.pdf:application/pdf;arXiv.org Snapshot:/home/harnist/Zotero/storage/XVEFISX3/1901.html:text/html},
}

@inproceedings{wang_multiscale_2003,
	address = {Pacific Grove, CA, USA},
	title = {Multiscale structural similarity for image quality assessment},
	isbn = {978-0-7803-8104-9},
	url = {http://ieeexplore.ieee.org/document/1292216/},
	doi = {10.1109/ACSSC.2003.1292216},
	language = {en},
	urldate = {2022-03-18},
	booktitle = {The {Thrity}-{Seventh} {Asilomar} {Conference} on {Signals}, {Systems} \& {Computers}, 2003},
	publisher = {IEEE},
	author = {Wang, Z. and Simoncelli, E.P. and Bovik, A.C.},
	year = {2003},
	pages = {1398--1402},
	file = {Wang et al. - 2003 - Multiscale structural similarity for image quality.pdf:/home/harnist/Zotero/storage/DWTIUX7H/Wang et al. - 2003 - Multiscale structural similarity for image quality.pdf:application/pdf},
}

@article{ryu_improved_2020,
	title = {Improved rainfall nowcasting using {Burgers}' equation},
	volume = {581},
	issn = {00221694},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0022169419308753},
	doi = {10.1016/j.jhydrol.2019.124140},
	abstract = {Nowcasting of surface precipitation from radar data typically relies on algorithms that calculate advection, such as the McGill Algorithm for Precipitation nowcasting by Lagrangian Extrapolation (MAPLE). This method offers high spatial and temporal resolution but it cannot represent the growth-decay of precipitation and non-stationary advection vector fields.},
	language = {en},
	urldate = {2022-03-18},
	journal = {Journal of Hydrology},
	author = {Ryu, Soorok and Lyu, Geunsu and Do, Younghae and Lee, GyuWon},
	month = feb,
	year = {2020},
	pages = {124140},
	file = {Ryu et al. - 2020 - Improved rainfall nowcasting using Burgers' equati.pdf:/home/harnist/Zotero/storage/K36W4S27/Ryu et al. - 2020 - Improved rainfall nowcasting using Burgers' equati.pdf:application/pdf;ScienceDirect Snapshot:/home/harnist/Zotero/storage/S8KN6Q4R/S0022169419308753.html:text/html},
}

@article{blundell_weight_2015,
	title = {Weight {Uncertainty} in {Neural} {Networks}},
	url = {http://arxiv.org/abs/1505.05424},
	abstract = {We introduce a new, efﬁcient, principled and backpropagation-compatible algorithm for learning a probability distribution on the weights of a neural network, called Bayes by Backprop. It regularises the weights by minimising a compression cost, known as the variational free energy or the expected lower bound on the marginal likelihood. We show that this principled kind of regularisation yields comparable performance to dropout on MNIST classiﬁcation. We then demonstrate how the learnt uncertainty in the weights can be used to improve generalisation in non-linear regression problems, and how this weight uncertainty can be used to drive the exploration-exploitation trade-off in reinforcement learning.},
	language = {en},
	urldate = {2022-03-21},
	journal = {arXiv:1505.05424 [cs, stat]},
	author = {Blundell, Charles and Cornebise, Julien and Kavukcuoglu, Koray and Wierstra, Daan},
	month = may,
	year = {2015},
	note = {arXiv: 1505.05424},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {Blundell et al. - 2015 - Weight Uncertainty in Neural Networks.pdf:/home/harnist/Zotero/storage/3UGR5FY5/Blundell et al. - 2015 - Weight Uncertainty in Neural Networks.pdf:application/pdf},
}

@article{pan_improving_2021,
	title = {Improving {Nowcasting} of {Convective} {Development} by {Incorporating} {Polarimetric} {Radar} {Variables} {Into} a {Deep}-{Learning} {Model}},
	volume = {48},
	issn = {1944-8007},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1029/2021GL095302},
	doi = {10.1029/2021GL095302},
	abstract = {Nowcasting of convective storms is urgently needed yet rather challenging. Current nowcasting methods are mostly based on radar echo extrapolation, which suffer from the insufficiency of input information and ineffectiveness of model architecture. A novel deep-learning (DL) model, FURENet, is designed for extracting information from multiple input variables to make predictions. Polarimetric radar variables, KDP and ZDR, which provide extra microphysics and dynamic structure information of storms, are fed into the model to improve nowcasting. Two representative cases indicate that KDP and ZDR can help the DL model better forecast convective organization and initiation. Quantitative statistical evaluation shows using FURENet, KDP, and ZDR synergistically improve nowcasting skills (CSI score) by 13.2\% and 17.4\% for the lead time of 30 and 60 min, respectively. Further evaluation shows the microphysical information provided by the polarimetric variables can enhance the DL model in understanding the evolution of convective storms and making more trustable nowcasts.},
	language = {en},
	number = {21},
	urldate = {2022-03-24},
	journal = {Geophysical Research Letters},
	author = {Pan, Xiang and Lu, Yinghui and Zhao, Kun and Huang, Hao and Wang, Mingjun and Chen, Haonan},
	year = {2021},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1029/2021GL095302},
	keywords = {deep learning, nowcasting, U-Net, convective precipitation, polarimetric radar},
	pages = {e2021GL095302},
	file = {Full Text PDF:/home/harnist/Zotero/storage/D5B2P5E4/Pan et al. - 2021 - Improving Nowcasting of Convective Development by .pdf:application/pdf;Snapshot:/home/harnist/Zotero/storage/JRC5B27U/2021GL095302.html:text/html},
}

@article{ayzel_rainnet_nodate,
	title = {{RainNet} v1.0: a convolutional neural network for radar-based precipitation nowcasting},
	abstract = {In this study, we present RainNet, a deep convolutional neural network for radar-based precipitation nowcasting. Its design was inspired by the U-Net and SegNet families of deep learning models which were originally designed for binary segmentation tasks. RainNet was trained to predict continuous precipitation intensities at a lead time of ﬁve minutes, using several years of quality-controlled weather radar composites provided by the German Weather Service (DWD). That data 5 set covers Germany with a spatial domain of 900×900 km, and has a resolution of 1 km in space and 5 minutes in time. Independent veriﬁcation experiments were carried out on eleven summer precipitation events from 2016 to 2017. In order to achieve a lead time of one hour, a recursive approach was implemented by using RainNet predictions at ﬁve minutes lead time as model input for longer lead times. In the veriﬁcation experiments, trivial Eulerian persistence and a conventional model based on optical ﬂow served as benchmarks. The latter is available in the rainymotion library, and had previously been shown 10 to outperform DWD’s operational nowcasting model for the same set of veriﬁcation events.},
	language = {en},
	author = {Ayzel, Georgy and Scheffer, Tobias and Heistermann, Maik},
	pages = {21},
	file = {Ayzel et al. - RainNet v1.0 a convolutional neural network for r.pdf:/home/harnist/Zotero/storage/CT2QNK7A/Ayzel et al. - RainNet v1.0 a convolutional neural network for r.pdf:application/pdf},
}

@article{yin_application_2021,
	title = {Application of a {Radar} {Echo} {Extrapolation}-{Based} {Deep} {Learning} {Method} in {Strong} {Convection} {Nowcasting}},
	volume = {8},
	issn = {2333-5084},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1029/2020EA001621},
	doi = {10.1029/2020EA001621},
	abstract = {Strong convection nowcasting has been gaining importance in operational weather forecasting. Recently, deep learning methods have been used to meet the increasing requirement for precise and timely nowcasting. One of the promising deep learning models is the convolutional gated recurrent unit (ConvGRU), which has been proven to perform better than traditional methods in strong convection nowcasting. Despite its encouraging performance, ConvGRU tends to produce blurry radar echo images and fails to model radar echo intensities that have multi-modal and skewed distributions. To overcome these disadvantages, we tested the structural similarity (SSIM) and multiscale structural similarity (MS-SSIM) indexes as loss functions. The SSIM and MS-SSIM loss functions are composed of luminance, contrast, and structure and provide more information about the intensity, grade, and shape of the radar echo, which can reduce blurring. Due to multi-layer downscaling, MS-SSIM extracted more radar echo characteristics, and its extrapolation was the most realistic and accurate among all of the loss function schemes. Only the MS-SSIM scheme successfully predicted strong radar echoes after 2 h, especially those at the rainstorm level.},
	language = {en},
	number = {8},
	urldate = {2022-03-28},
	journal = {Earth and Space Science},
	author = {Yin, Jian and Gao, Zhiqiu and Han, Wei},
	year = {2021},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1029/2020EA001621},
	keywords = {deep learning, nowcasting, radar echo extrapolation},
	pages = {e2020EA001621},
	file = {Full Text PDF:/home/harnist/Zotero/storage/SWTZWMTM/Yin et al. - 2021 - Application of a Radar Echo Extrapolation-Based De.pdf:application/pdf;Snapshot:/home/harnist/Zotero/storage/P3P86497/2020EA001621.html:text/html},
}

@article{zhao_loss_2017,
	title = {Loss {Functions} for {Image} {Restoration} {With} {Neural} {Networks}},
	volume = {3},
	issn = {2333-9403},
	doi = {10.1109/TCI.2016.2644865},
	abstract = {Neural networks are becoming central in several areas of computer vision and image processing and different architectures have been proposed to solve specific problems. The impact of the loss layer of neural networks, however, has not received much attention in the context of image processing: the default and virtually only choice is ℓ2. In this paper, we bring attention to alternative choices for image restoration. In particular, we show the importance of perceptually-motivated losses when the resulting image is to be evaluated by a human observer. We compare the performance of several losses, and propose a novel, differentiable error function. We show that the quality of the results improves significantly with better loss functions, even when the network architecture is left unchanged.},
	number = {1},
	journal = {IEEE Transactions on Computational Imaging},
	author = {Zhao, Hang and Gallo, Orazio and Frosio, Iuri and Kautz, Jan},
	month = mar,
	year = {2017},
	note = {Conference Name: IEEE Transactions on Computational Imaging},
	keywords = {Neural networks, Measurement, neural networks, Image processing, Image quality, image restoration, Image restoration, loss functions},
	pages = {47--57},
	file = {IEEE Xplore Abstract Record:/home/harnist/Zotero/storage/69499HEH/7797130.html:text/html;IEEE Xplore Full Text PDF:/home/harnist/Zotero/storage/5DIXBZ39/Zhao et al. - 2017 - Loss Functions for Image Restoration With Neural N.pdf:application/pdf},
}

@article{prudden_review_2020,
	title = {A review of radar-based nowcasting of precipitation and applicable machine learning techniques},
	url = {http://arxiv.org/abs/2005.04988},
	abstract = {A ‘nowcast’ is a type of weather forecast which makes predictions in the very short term, typically less than two hours - a period in which traditional numerical weather prediction can be limited. This type of weather prediction has important applications for commercial aviation; public and outdoor events; and the construction industry, power utilities, and ground transportation services that conduct much of their work outdoors. Importantly, one of the key needs for nowcasting systems is in the provision of accurate warnings of adverse weather events, such as heavy rain and ﬂooding, for the protection of life and property in such situations. Typical nowcasting approaches are based on simple extrapolation models applied to observations, primarily rainfall radar. In this paper we review existing techniques to radar-based nowcasting from environmental sciences, as well as the statistical approaches that are applicable from the ﬁeld of machine learning. Nowcasting continues to be an important component of operational systems and we believe new advances are possible with new partnerships between the environmental science and machine learning communities.},
	language = {en},
	urldate = {2022-03-30},
	journal = {arXiv:2005.04988 [physics, stat]},
	author = {Prudden, Rachel and Adams, Samantha and Kangin, Dmitry and Robinson, Niall and Ravuri, Suman and Mohamed, Shakir and Arribas, Alberto},
	month = may,
	year = {2020},
	note = {arXiv: 2005.04988},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Physics - Atmospheric and Oceanic Physics},
	file = {Prudden et al. - 2020 - A review of radar-based nowcasting of precipitatio.pdf:/home/harnist/Zotero/storage/IHWXM9WN/Prudden et al. - 2020 - A review of radar-based nowcasting of precipitatio.pdf:application/pdf},
}

@article{franch_taasrad19_2020,
	title = {{TAASRAD19}, a high-resolution weather radar reflectivity dataset for precipitation nowcasting},
	volume = {7},
	copyright = {2020 The Author(s)},
	issn = {2052-4463},
	url = {https://www.nature.com/articles/s41597-020-0574-8},
	doi = {10.1038/s41597-020-0574-8},
	abstract = {We introduce TAASRAD19, a high-resolution radar reflectivity dataset collected by the Civil Protection weather radar of the Trentino South Tyrol Region, in the Italian Alps. The dataset includes 894,916 timesteps of precipitation from more than 9 years of data, offering a novel resource to develop and benchmark analog ensemble models and machine learning solutions for precipitation nowcasting. Data are expressed as 2D images, considering the maximum reflectivity on the vertical section at 5 min sampling rate, covering an area of 240 km of diameter at 500 m horizontal resolution. The TAASRAD19 distribution also includes a curated set of 1,732 sequences, for a total of 362,233 radar images, labeled with precipitation type tags assigned by expert meteorologists. We validate TAASRAD19 as a benchmark for nowcasting methods by introducing a TrajGRU deep learning model to forecast reflectivity, and a procedure based on the UMAP dimensionality reduction algorithm for interactive exploration. Software methods for data pre-processing, model training and inference, and a pre-trained model are publicly available on GitHub (https://github.com/MPBA/TAASRAD19) for study replication and reproducibility.},
	language = {en},
	number = {1},
	urldate = {2022-04-07},
	journal = {Scientific Data},
	author = {Franch, Gabriele and Maggio, Valerio and Coviello, Luca and Pendesini, Marta and Jurman, Giuseppe and Furlanello, Cesare},
	month = jul,
	year = {2020},
	note = {Number: 1
Publisher: Nature Publishing Group},
	keywords = {Atmospheric dynamics, Computational science},
	pages = {234},
	file = {Full Text PDF:/home/harnist/Zotero/storage/7KASMA3J/Franch et al. - 2020 - TAASRAD19, a high-resolution weather radar reflect.pdf:application/pdf;Snapshot:/home/harnist/Zotero/storage/J6HJN5T6/s41597-020-0574-8.html:text/html},
}

@article{schultz_can_2021,
	title = {Can deep learning beat numerical weather prediction?},
	volume = {379},
	url = {https://royalsocietypublishing.org/doi/10.1098/rsta.2020.0097},
	doi = {10.1098/rsta.2020.0097},
	abstract = {The recent hype about artificial intelligence has sparked renewed interest in applying the successful deep learning (DL) methods for image recognition, speech recognition, robotics, strategic games and other application areas to the field of meteorology. There is some evidence that better weather forecasts can be produced by introducing big data mining and neural networks into the weather prediction workflow. Here, we discuss the question of whether it is possible to completely replace the current numerical weather models and data assimilation systems with DL approaches. This discussion entails a review of state-of-the-art machine learning concepts and their applicability to weather data with its pertinent statistical properties. We think that it is not inconceivable that numerical weather models may one day become obsolete, but a number of fundamental breakthroughs are needed before this goal comes into reach.

This article is part of the theme issue ‘Machine learning for weather and climate modelling’.},
	number = {2194},
	urldate = {2022-04-14},
	journal = {Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
	author = {Schultz, M. G. and Betancourt, C. and Gong, B. and Kleinert, F. and Langguth, M. and Leufen, L. H. and Mozaffari, A. and Stadtler, S.},
	month = apr,
	year = {2021},
	note = {Publisher: Royal Society},
	keywords = {deep learning, machine learning, numerical weather prediction, spatiotemporal pattern recognition, weather AI},
	pages = {20200097},
	file = {Full Text PDF:/home/harnist/Zotero/storage/WRWXYS7G/Schultz et al. - 2021 - Can deep learning beat numerical weather predictio.pdf:application/pdf},
}

@article{kingma_variational_2015,
	title = {Variational {Dropout} and the {Local} {Reparameterization} {Trick}},
	url = {http://arxiv.org/abs/1506.02557},
	abstract = {We investigate a local reparameterizaton technique for greatly reducing the variance of stochastic gradients for variational Bayesian inference (SGVB) of a posterior over model parameters, while retaining parallelizability. This local reparameterization translates uncertainty about global parameters into local noise that is independent across datapoints in the minibatch. Such parameterizations can be trivially parallelized and have variance that is inversely proportional to the minibatch size, generally leading to much faster convergence. Additionally, we explore a connection with dropout: Gaussian dropout objectives correspond to SGVB with local reparameterization, a scale-invariant prior and proportionally ﬁxed posterior variance. Our method allows inference of more ﬂexibly parameterized posteriors; speciﬁcally, we propose variational dropout, a generalization of Gaussian dropout where the dropout rates are learned, often leading to better models. The method is demonstrated through several experiments.},
	language = {en},
	urldate = {2022-04-23},
	journal = {arXiv:1506.02557 [cs, stat]},
	author = {Kingma, Diederik P. and Salimans, Tim and Welling, Max},
	month = dec,
	year = {2015},
	note = {arXiv: 1506.02557},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Statistics - Computation},
	file = {Kingma et al. - 2015 - Variational Dropout and the Local Reparameterizati.pdf:/home/harnist/Zotero/storage/3WLN42UA/Kingma et al. - 2015 - Variational Dropout and the Local Reparameterizati.pdf:application/pdf},
}

@article{kendall_what_2017,
	title = {What {Uncertainties} {Do} {We} {Need} in {Bayesian} {Deep} {Learning} for {Computer} {Vision}?},
	url = {http://arxiv.org/abs/1703.04977},
	abstract = {There are two major types of uncertainty one can model. Aleatoric uncertainty captures noise inherent in the observations. On the other hand, epistemic uncertainty accounts for uncertainty in the model -- uncertainty which can be explained away given enough data. Traditionally it has been difficult to model epistemic uncertainty in computer vision, but with new Bayesian deep learning tools this is now possible. We study the benefits of modeling epistemic vs. aleatoric uncertainty in Bayesian deep learning models for vision tasks. For this we present a Bayesian deep learning framework combining input-dependent aleatoric uncertainty together with epistemic uncertainty. We study models under the framework with per-pixel semantic segmentation and depth regression tasks. Further, our explicit uncertainty formulation leads to new loss functions for these tasks, which can be interpreted as learned attenuation. This makes the loss more robust to noisy data, also giving new state-of-the-art results on segmentation and depth regression benchmarks.},
	urldate = {2022-05-02},
	journal = {arXiv:1703.04977 [cs]},
	author = {Kendall, Alex and Gal, Yarin},
	month = oct,
	year = {2017},
	note = {arXiv: 1703.04977},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:/home/harnist/Zotero/storage/5IPAGIW7/Kendall and Gal - 2017 - What Uncertainties Do We Need in Bayesian Deep Lea.pdf:application/pdf;arXiv.org Snapshot:/home/harnist/Zotero/storage/UWYCDGER/1703.html:text/html},
}

@article{sakaino_spatio-temporal_2013,
	title = {Spatio-{Temporal} {Image} {Pattern} {Prediction} {Method} {Based} on a {Physical} {Model} {With} {Time}-{Varying} {Optical} {Flow}},
	volume = {51},
	issn = {1558-0644},
	doi = {10.1109/TGRS.2012.2212201},
	abstract = {This paper proposes an image-based prediction method that can physically predict near-future spatio-temporal image changes using fluid-like image sequences, i.e., dynamic texture, from different image sources such as ground-based radar imagers, satellite sensors, and lightning detectors. Previous alternatives, i.e., tracking radar echo by correlation or thunderstorm identification, tracking, analysis, and nowcasting, employ pattern matching or linear extrapolation of the centroid of an image object to predict the next time image with many tuning model parameters. However, such methods fail to handle the high degree of motion and deformation of fluid-like images, i.e., vortex. To remedy this issue, this paper presents a spatio-temporal prediction method based on a computer vision framework; it employs a physics-based model with time-variant optical flow. Initial local motions from image sequences are estimated by the extended optical flow method, where a locally optimal weighting parameter and a statistically robust function are applied to Horn and Schunck's model. The next time image sequence from the past image sequence is physically predicted by the extended advection equation for image intensities and the Navier–Stokes equation with a continuity equation for varying optical flow over time. For different source images, our method offers no prior knowledge of size, shape, texture, and motion of moving objects. Experiments demonstrate that the proposed prediction method outperforms a previous prediction method with respect to prediction accuracy.},
	number = {5},
	journal = {IEEE Transactions on Geoscience and Remote Sensing},
	author = {Sakaino, Hidetomo},
	month = may,
	year = {2013},
	note = {Conference Name: IEEE Transactions on Geoscience and Remote Sensing},
	keywords = {radar, Computational modeling, Mathematical model, Predictive models, Meteorology, optical flow, Advection, computer vision, Computer vision, detector, Nonlinear optics, Optical imaging, Optical sensors, physical model, prediction, sensor, spatio-temporal change, weather},
	pages = {3023--3036},
	file = {IEEE Xplore Abstract Record:/home/harnist/Zotero/storage/QS4CJLRH/6310050.html:text/html;IEEE Xplore Full Text PDF:/home/harnist/Zotero/storage/PFEJTR33/Sakaino - 2013 - Spatio-Temporal Image Pattern Prediction Method Ba.pdf:application/pdf},
}

@article{bowler_steps_2006,
	title = {{STEPS}: {A} probabilistic precipitation forecasting scheme which merges an extrapolation nowcast with downscaled {NWP}},
	volume = {132},
	issn = {1477-870X},
	shorttitle = {{STEPS}},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1256/qj.04.100},
	doi = {10.1256/qj.04.100},
	abstract = {An ensemble-based probabilistic precipitation forecasting scheme has been developed that blends an extrapolation nowcast with a downscaled NWP forecast, known as STEPS: Short-Term Ensemble Prediction System. The uncertainties in the motion and evolution of radar-inferred precipitation fields are quantified, and the uncertainty in the evolution of the precipitation pattern is shown to be the more important. The use of ensembles allows the scheme to be used for applications that require forecasts of the probability density function of areal and temporal averages of precipitation, such as fluvial flood forecasting—a capability that has not been provided by previous probabilistic precipitation nowcast schemes. The output from a NWP forecast model is downscaled so that the small scales not represented accurately by the model are injected into the forecast using stochastic noise. This allows the scheme to better represent the distribution of precipitation rate at spatial scales finer than those adequately resolved by operational NWP. The performance of the scheme has been assessed over the month of March 2003. Performance evaluation statistics show that the scheme possesses predictive skill at lead times in excess of six hours. © Crown copyright, 2006.},
	language = {en},
	number = {620},
	urldate = {2022-06-05},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Bowler, Neill E. and Pierce, Clive E. and Seed, Alan W.},
	year = {2006},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1256/qj.04.100},
	keywords = {Ensemble, Noise cascade, S-PROG},
	pages = {2127--2155},
	file = {Snapshot:/home/harnist/Zotero/storage/BM59WJDX/qj.04.html:text/html},
}

@article{pulkkinen_lagrangian_2021,
	title = {Lagrangian {Integro}-{Difference} {Equation} {Model} for {Precipitation} {Nowcasting}},
	volume = {38},
	issn = {0739-0572, 1520-0426},
	url = {https://journals.ametsoc.org/view/journals/atot/38/12/JTECH-D-21-0013.1.xml},
	doi = {10.1175/JTECH-D-21-0013.1},
	abstract = {Abstract Delivering reliable nowcasts (short-range forecasts) of severe rainfall and the resulting flash floods is important in densely populated urban areas. The conventional method is advection-based extrapolation of radar echoes. However, during rapidly evolving convective rainfall this so-called Lagrangian persistence (LP) approach is limited to deterministic and very short-range nowcasts. To address these limitations in the 1-h time range, a novel extension of LP, called Lagrangian Integro-Difference equation model with Autoregression (LINDA), is proposed. The model consists of five components: 1) identification of rain cells, 2) advection, 3) autoregressive process describing growth and decay of the cells, 4) convolution describing loss of predictability at small scales, and 5) stochastic perturbations to simulate forecast uncertainty. Advection is separated from the other components that are applied in the Lagrangian coordinates. The reliability of LINDA is evaluated using the NEXRAD WSR-88D radar that covers the Dallas–Fort Worth metropolitan area, as well as the NEXRAD mosaic covering the continental United States. This is done with two different configurations: LINDA-D for deterministic and LINDA-P for probabilistic nowcasts. The validation dataset consists of 11 rainfall events during 2018–20. For predicting moderate to heavy rainfall (5–20 mm h−1), LINDA outperforms the previously proposed LP-based approaches. The most significant improvement is seen for the ETS and POD statistics with the 5 mm h−1 threshold. For 30-min nowcasts, they show 15\% and 16\% increases, respectively, to the second-best method and 48\% and 34\% increases compared to LP. For the 5 mm h−1 threshold, the increase in the relative operating characteristic (ROC) skill score of 30-min nowcasts from the second-best method is 10\%. Significance Statement Delivering reliable forecasts of severe rainfall for the next few hours has a major societal importance. This is particularly true for densely populated urban areas, where flash floods can cause property damage and loss of lives. Such forecasts are conventionally produced by direct extrapolation of weather radar measurements. However, for intense localized rainfall this approach has low prediction ability beyond 30 min. To extend this limit, we propose a novel method that combines machine vision with a statistical model for growth and decay of rainfall. The method is designed for predicting highly localized rain cells and bands. In addition, a stochastic extension for producing probabilistic forecasts is developed. Using several verification metrics, we demonstrate that for predicting moderate to heavy rainfall (5–20 mm h−1), the proposed method has significantly improved forecast skill compared to the reference methods. The evaluation is done by using the NEXRAD WSR-88D that covers the Dallas–Fort Worth urban metroplex with a population of over 7 million. Demonstration of the applicability of LINDA in a larger domain is done by using the NEXRAD radar network that covers the continental United States.},
	language = {EN},
	number = {12},
	urldate = {2022-06-05},
	journal = {Journal of Atmospheric and Oceanic Technology},
	author = {Pulkkinen, Seppo and Chandrasekar, V. and Niemi, Tero},
	month = dec,
	year = {2021},
	note = {Publisher: American Meteorological Society
Section: Journal of Atmospheric and Oceanic Technology},
	pages = {2125--2145},
	file = {Snapshot:/home/harnist/Zotero/storage/XALGXCJ2/JTECH-D-21-0013.1.html:text/html},
}

@article{ravuri_skilful_2021,
	title = {Skilful precipitation nowcasting using deep generative models of radar},
	volume = {597},
	copyright = {2021 The Author(s)},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/s41586-021-03854-z},
	doi = {10.1038/s41586-021-03854-z},
	abstract = {Precipitation nowcasting, the high-resolution forecasting of precipitation up to two hours ahead, supports the real-world socioeconomic needs of many sectors reliant on weather-dependent decision-making1,2. State-of-the-art operational nowcasting methods typically advect precipitation fields with radar-based wind estimates, and struggle to capture important non-linear events such as convective initiations3,4. Recently introduced deep learning methods use radar to directly predict future rain rates, free of physical constraints5,6. While they accurately predict low-intensity rainfall, their operational utility is limited because their lack of constraints produces blurry nowcasts at longer lead times, yielding poor performance on rarer medium-to-heavy rain events. Here we present a deep generative model for the probabilistic nowcasting of precipitation from radar that addresses these challenges. Using statistical, economic and cognitive measures, we show that our method provides improved forecast quality, forecast consistency and forecast value. Our model produces realistic and spatiotemporally consistent predictions over regions up to 1,536 km × 1,280 km and with lead times from 5–90 min ahead. Using a systematic evaluation by more than 50 expert meteorologists, we show that our generative model ranked first for its accuracy and usefulness in 89\% of cases against two competitive methods. When verified quantitatively, these nowcasts are skillful without resorting to blurring. We show that generative nowcasting can provide probabilistic predictions that improve forecast value and support operational utility, and at resolutions and lead times where alternative methods struggle.},
	language = {en},
	number = {7878},
	urldate = {2022-06-05},
	journal = {Nature},
	author = {Ravuri, Suman and Lenc, Karel and Willson, Matthew and Kangin, Dmitry and Lam, Remi and Mirowski, Piotr and Fitzsimons, Megan and Athanassiadou, Maria and Kashem, Sheleem and Madge, Sam and Prudden, Rachel and Mandhane, Amol and Clark, Aidan and Brock, Andrew and Simonyan, Karen and Hadsell, Raia and Robinson, Niall and Clancy, Ellen and Arribas, Alberto and Mohamed, Shakir},
	month = sep,
	year = {2021},
	note = {Number: 7878
Publisher: Nature Publishing Group},
	keywords = {Computer science, Environmental sciences},
	pages = {672--677},
	file = {Full Text PDF:/home/harnist/Zotero/storage/HQ5EZ7YS/Ravuri et al. - 2021 - Skilful precipitation nowcasting using deep genera.pdf:application/pdf;Snapshot:/home/harnist/Zotero/storage/LKG6QAWB/s41586-021-03854-z.html:text/html},
}

@article{mcallister_concrete_2017,
	title = {Concrete {Problems} for {Autonomous} {Vehicle} {Safety}: {Advantages} of {Bayesian} {Deep} {Learning}},
	shorttitle = {Concrete {Problems} for {Autonomous} {Vehicle} {Safety}},
	url = {https://www.ijcai.org/proceedings/2017/661},
	abstract = {Electronic proceedings of IJCAI 2017},
	urldate = {2022-06-05},
	author = {McAllister, Rowan and Gal, Yarin and Kendall, Alex and Wilk, Mark van der and Shah, Amar and Cipolla, Roberto and Weller, Adrian},
	year = {2017},
	pages = {4745--4753},
	file = {Snapshot:/home/harnist/Zotero/storage/V3XWLAH6/661.html:text/html},
}

@article{kwon_uncertainty_2020,
	title = {Uncertainty quantification using {Bayesian} neural networks in classification: {Application} to biomedical image segmentation},
	volume = {142},
	issn = {0167-9473},
	shorttitle = {Uncertainty quantification using {Bayesian} neural networks in classification},
	url = {https://www.sciencedirect.com/science/article/pii/S016794731930163X},
	doi = {10.1016/j.csda.2019.106816},
	abstract = {Most recent research of deep neural networks in the field of computer vision has focused on improving performances of point predictions by developing network architectures or learning algorithms. Reliable uncertainty quantification accompanied by point estimation can lead to a more informed decision, and the quality of prediction can be improved. In this paper, we invoke a Bayesian neural network and propose a natural way of quantifying uncertainties in classification problems by decomposing the moment-based predictive uncertainty into two parts: aleatoric and epistemic uncertainty. The proposed method takes into account the discrete nature of the outcome, yielding the correct interpretation of each uncertainty. We demonstrate that the proposed uncertainty quantification method provides additional insights into the point prediction using two Ischemic Stroke Lesion Segmentation Challenge datasets and the Digital Retinal Images for Vessel Extraction dataset.},
	language = {en},
	urldate = {2022-06-05},
	journal = {Computational Statistics \& Data Analysis},
	author = {Kwon, Yongchan and Won, Joong-Ho and Kim, Beom Joon and Paik, Myunghee Cho},
	month = feb,
	year = {2020},
	keywords = {Aleatoric and epistemic uncertainty, Bayesian neural network, Ischemic stroke lesion segmentation, Retinal blood vessel segmentation, Uncertainty quantification},
	pages = {106816},
	file = {ScienceDirect Snapshot:/home/harnist/Zotero/storage/ULPTAHPZ/S016794731930163X.html:text/html},
}

@misc{ziyin_neural_2020,
	title = {Neural {Networks} {Fail} to {Learn} {Periodic} {Functions} and {How} to {Fix} {It}},
	url = {http://arxiv.org/abs/2006.08195},
	abstract = {Previous literature offers limited clues on how to learn a periodic function using modern neural networks. We start with a study of the extrapolation properties of neural networks; we prove and demonstrate experimentally that the standard activations functions, such as ReLU, tanh, sigmoid, along with their variants, all fail to learn to extrapolate simple periodic functions. We hypothesize that this is due to their lack of a “periodic” inductive bias. As a ﬁx of this problem, we propose a new activation, namely, x + sin2(x), which achieves the desired periodic inductive bias to learn a periodic function while maintaining a favorable optimization property of the ReLU-based activations. Experimentally, we apply the proposed method to temperature and ﬁnancial data prediction.},
	language = {en},
	urldate = {2022-06-06},
	publisher = {arXiv},
	author = {Ziyin, Liu and Hartwig, Tilman and Ueda, Masahito},
	month = oct,
	year = {2020},
	note = {Number: arXiv:2006.08195
arXiv:2006.08195 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {Ziyin et al. - 2020 - Neural Networks Fail to Learn Periodic Functions a.pdf:/home/harnist/Zotero/storage/IMPNBHCX/Ziyin et al. - 2020 - Neural Networks Fail to Learn Periodic Functions a.pdf:application/pdf},
}

@misc{ziyin_neural_2020-1,
	title = {Neural {Networks} {Fail} to {Learn} {Periodic} {Functions} and {How} to {Fix} {It}},
	url = {http://arxiv.org/abs/2006.08195},
	abstract = {Previous literature offers limited clues on how to learn a periodic function using modern neural networks. We start with a study of the extrapolation properties of neural networks; we prove and demonstrate experimentally that the standard activations functions, such as ReLU, tanh, sigmoid, along with their variants, all fail to learn to extrapolate simple periodic functions. We hypothesize that this is due to their lack of a “periodic” inductive bias. As a ﬁx of this problem, we propose a new activation, namely, x + sin2(x), which achieves the desired periodic inductive bias to learn a periodic function while maintaining a favorable optimization property of the ReLU-based activations. Experimentally, we apply the proposed method to temperature and ﬁnancial data prediction.},
	language = {en},
	urldate = {2022-06-06},
	publisher = {arXiv},
	author = {Ziyin, Liu and Hartwig, Tilman and Ueda, Masahito},
	month = oct,
	year = {2020},
	note = {Number: arXiv:2006.08195
arXiv:2006.08195 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {Ziyin et al. - 2020 - Neural Networks Fail to Learn Periodic Functions a.pdf:/home/harnist/Zotero/storage/6PYDCR6B/Ziyin et al. - 2020 - Neural Networks Fail to Learn Periodic Functions a.pdf:application/pdf},
}

@article{pulkkinen_pysteps_2019,
	title = {Pysteps: an open-source {Python} library for probabilistic precipitation nowcasting (v1.0)},
	volume = {12},
	issn = {1991-959X},
	shorttitle = {Pysteps},
	url = {https://gmd.copernicus.org/articles/12/4185/2019/},
	doi = {10.5194/gmd-12-4185-2019},
	abstract = {{\textless}p{\textgreater}{\textless}strong class="journal-contentHeaderColor"{\textgreater}Abstract.{\textless}/strong{\textgreater} Pysteps is an open-source and community-driven Python library for probabilistic precipitation nowcasting, that is, very-short-range forecasting (0–6\&thinsp;h). The aim of pysteps is to serve two different needs. The first is to provide a modular and well-documented framework for researchers interested in developing new methods for nowcasting and stochastic space–time simulation of precipitation. The second aim is to offer a highly configurable and easily accessible platform for practitioners ranging from weather forecasters to hydrologists. In this sense, pysteps has the potential to become an important component for integrated early warning systems for severe weather.{\textless}/p{\textgreater} {\textless}p{\textgreater}The pysteps library supports various input/output file formats and implements several optical flow methods as well as advanced stochastic generators to produce ensemble nowcasts. In addition, it includes tools for visualizing and post-processing the nowcasts and methods for deterministic, probabilistic and neighborhood forecast verification. The pysteps library is described and its potential is demonstrated using radar composite images from Finland, Switzerland, the United States and Australia. Finally, scientific experiments are carried out to help the reader to understand the pysteps framework and sensitivity to model parameters.{\textless}/p{\textgreater}},
	language = {English},
	number = {10},
	urldate = {2022-06-13},
	journal = {Geoscientific Model Development},
	author = {Pulkkinen, Seppo and Nerini, Daniele and Pérez Hortal, Andrés A. and Velasco-Forero, Carlos and Seed, Alan and Germann, Urs and Foresti, Loris},
	month = oct,
	year = {2019},
	note = {Publisher: Copernicus GmbH},
	pages = {4185--4219},
	file = {Full Text PDF:/home/harnist/Zotero/storage/5KRQPZJG/Pulkkinen et al. - 2019 - Pysteps an open-source Python library for probabi.pdf:application/pdf;Snapshot:/home/harnist/Zotero/storage/HHJ5MKIS/2019.html:text/html},
}

@article{roberts_scale-selective_2008,
	title = {Scale-{Selective} {Verification} of {Rainfall} {Accumulations} from {High}-{Resolution} {Forecasts} of {Convective} {Events}},
	volume = {136},
	issn = {1520-0493, 0027-0644},
	url = {https://journals.ametsoc.org/view/journals/mwre/136/1/2007mwr2123.1.xml},
	doi = {10.1175/2007MWR2123.1},
	abstract = {Abstract The development of NWP models with grid spacing down to ∼1 km should produce more realistic forecasts of convective storms. However, greater realism does not necessarily mean more accurate precipitation forecasts. The rapid growth of errors on small scales in conjunction with preexisting errors on larger scales may limit the usefulness of such models. The purpose of this paper is to examine whether improved model resolution alone is able to produce more skillful precipitation forecasts on useful scales, and how the skill varies with spatial scale. A verification method will be described in which skill is determined from a comparison of rainfall forecasts with radar using fractional coverage over different sized areas. The Met Office Unified Model was run with grid spacings of 12, 4, and 1 km for 10 days in which convection occurred during the summers of 2003 and 2004. All forecasts were run from 12-km initial states for a clean comparison. The results show that the 1-km model was the most skillful over all but the smallest scales (approximately {\textless}10–15 km). A measure of acceptable skill was defined; this was attained by the 1-km model at scales around 40–70 km, some 10–20 km less than that of the 12-km model. The biggest improvement occurred for heavier, more localized rain, despite it being more difficult to predict. The 4-km model did not improve much on the 12-km model because of the difficulties of representing convection at that resolution, which was accentuated by the spinup from 12-km fields.},
	language = {EN},
	number = {1},
	urldate = {2022-06-20},
	journal = {Monthly Weather Review},
	author = {Roberts, Nigel M. and Lean, Humphrey W.},
	month = jan,
	year = {2008},
	note = {Publisher: American Meteorological Society
Section: Monthly Weather Review},
	pages = {78--97},
	file = {Full Text PDF:/home/harnist/Zotero/storage/TFMNVQIN/Roberts and Lean - 2008 - Scale-Selective Verification of Rainfall Accumulat.pdf:application/pdf;Snapshot:/home/harnist/Zotero/storage/ASGW6IZM/2007mwr2123.1.html:text/html},
}

@article{minka_family_nodate,
	title = {A family of algorithms for approximate {Bayesian} inference},
	abstract = {One of the major obstacles to using Bayesian methods for pattern recognition has been its computational expense. This thesis presents an approximation technique that can perform Bayesian inference faster and more accurately than previously possible. This method, "Expectation Propagation," unifies and generalizes two previous techniques: assumeddensity filtering, an extension of the Kalman filter, and loopy belief propagation, an extension of belief propagation in Bayesian networks. The unification shows how both of these algorithms can be viewed as approximating the true posterior distribution with a simpler distribution, which is close in the sense of KL-divergence. Expectation Propagation exploits the best of both algorithms: the generality of assumed-density filtering and the accuracy of loopy belief propagation. Loopy belief propagation, because it propagates exact belief states, is useful for limited types of belief networks, such as purely discrete networks. Expectation Propagation approximates the belief states with expectations, such as means and variances, giving it much wider scope. Expectation Propagation also extends belief propagation in the opposite direction-propagating richer belief states which incorporate correlations between variables. This framework is demonstrated in a variety of statistical models using synthetic and real-world data. On Gaussian mixture problems, Expectation Propagation is found, for the same amount of computation, to be convincingly better than rival approximation techniques: Monte Carlo, Laplace's method, and variational Bayes. For pattern recognition, Expectation Propagation provides an algorithm for training Bayes Point Machine classifiers that is faster and more accurate than any previously known. The resulting classifiers outperform Support Vector Machines on several standard datasets, in addition to having a comparable training time. Expectation Propagation can also be used to choose an appropriate feature set for classification, via Bayesian model selection.},
	language = {en},
	author = {Minka, Thomas P},
	pages = {75},
	file = {Minka - A family of algorithms for approximate Bayesian in.pdf:/home/harnist/Zotero/storage/7ZMD7R6V/Minka - A family of algorithms for approximate Bayesian in.pdf:application/pdf},
}

@article{minka_family_nodate-1,
	title = {A family of algorithms for approximate {Bayesian} inference},
	abstract = {One of the major obstacles to using Bayesian methods for pattern recognition has been its computational expense. This thesis presents an approximation technique that can perform Bayesian inference faster and more accurately than previously possible. This method, "Expectation Propagation," unifies and generalizes two previous techniques: assumeddensity filtering, an extension of the Kalman filter, and loopy belief propagation, an extension of belief propagation in Bayesian networks. The unification shows how both of these algorithms can be viewed as approximating the true posterior distribution with a simpler distribution, which is close in the sense of KL-divergence. Expectation Propagation exploits the best of both algorithms: the generality of assumed-density filtering and the accuracy of loopy belief propagation. Loopy belief propagation, because it propagates exact belief states, is useful for limited types of belief networks, such as purely discrete networks. Expectation Propagation approximates the belief states with expectations, such as means and variances, giving it much wider scope. Expectation Propagation also extends belief propagation in the opposite direction-propagating richer belief states which incorporate correlations between variables. This framework is demonstrated in a variety of statistical models using synthetic and real-world data. On Gaussian mixture problems, Expectation Propagation is found, for the same amount of computation, to be convincingly better than rival approximation techniques: Monte Carlo, Laplace's method, and variational Bayes. For pattern recognition, Expectation Propagation provides an algorithm for training Bayes Point Machine classifiers that is faster and more accurate than any previously known. The resulting classifiers outperform Support Vector Machines on several standard datasets, in addition to having a comparable training time. Expectation Propagation can also be used to choose an appropriate feature set for classification, via Bayesian model selection.},
	language = {en},
	author = {Minka, Thomas P},
	pages = {75},
	file = {Minka - A family of algorithms for approximate Bayesian in.pdf:/home/harnist/Zotero/storage/CF5FF3JY/Minka - A family of algorithms for approximate Bayesian in.pdf:application/pdf},
}

@article{graves_practical_2011,
	title = {Practical {Variational} {Inference} for {Neural} {Networks}},
	abstract = {Variational methods have been previously explored as a tractable approximation to Bayesian inference for neural networks. However the approaches proposed so far have only been applicable to a few simple network architectures. This paper introduces an easy-to-implement stochastic variational method (or equivalently, minimum description length loss function) that can be applied to most neural networks. Along the way it revisits several common regularisers from a variational perspective. It also provides a simple pruning heuristic that can both drastically reduce the number of network weights and lead to improved generalisation. Experimental results are provided for a hierarchical multidimensional recurrent neural network applied to the TIMIT speech corpus.},
	language = {en},
	author = {Graves, Alex},
	year = {2011},
	pages = {9},
	file = {Graves - Practical Variational Inference for Neural Network.pdf:/home/harnist/Zotero/storage/RZVB4ZH8/Graves - Practical Variational Inference for Neural Network.pdf:application/pdf},
}

@article{hinton_keeping_1993,
	title = {Keeping {Neural} {Networks} {Simple} by {Minimizing} the {Description} {Length} of the {Weights}},
	abstract = {Supervised neural networks generalize well if there is much less information in the weights than there is in the output vectors of the training cases. So during learning, it is important to keep the weights simple by penalizing the amount of information they contain. The amount of information in a weight can be controlled by adding Gaussian noise and the noise level can be adapted during learning to optimize the trade-off between the expected squared error of the network and the amount of information in the weights. We describe a method of computing the derivatives of the expected squared error and of the amount of information in the noisy weights in a network that contains a layer of non-linear hidden units. Provided the output units are linear, the exact derivatives can be computed efficiently without time-consuming Monte Carlo simulations. The idea of minimizing the amount of information that is required to communicate the weights of a neural network leads to a number of intereating schemes for encoding the weights.},
	language = {en},
	author = {Hinton, E},
	year = {1993},
	pages = {9},
	file = {Hinton - Keeping Neural Networks Simple by Minimizing the D.pdf:/home/harnist/Zotero/storage/J8JL6VNU/Hinton - Keeping Neural Networks Simple by Minimizing the D.pdf:application/pdf},
}

@misc{wen_flipout_2018,
	title = {Flipout: {Efficient} {Pseudo}-{Independent} {Weight} {Perturbations} on {Mini}-{Batches}},
	shorttitle = {Flipout},
	url = {http://arxiv.org/abs/1803.04386},
	doi = {10.48550/arXiv.1803.04386},
	abstract = {Stochastic neural net weights are used in a variety of contexts, including regularization, Bayesian neural nets, exploration in reinforcement learning, and evolution strategies. Unfortunately, due to the large number of weights, all the examples in a mini-batch typically share the same weight perturbation, thereby limiting the variance reduction effect of large mini-batches. We introduce flipout, an efficient method for decorrelating the gradients within a mini-batch by implicitly sampling pseudo-independent weight perturbations for each example. Empirically, flipout achieves the ideal linear variance reduction for fully connected networks, convolutional networks, and RNNs. We find significant speedups in training neural networks with multiplicative Gaussian perturbations. We show that flipout is effective at regularizing LSTMs, and outperforms previous methods. Flipout also enables us to vectorize evolution strategies: in our experiments, a single GPU with flipout can handle the same throughput as at least 40 CPU cores using existing methods, equivalent to a factor-of-4 cost reduction on Amazon Web Services.},
	urldate = {2022-06-23},
	publisher = {arXiv},
	author = {Wen, Yeming and Vicol, Paul and Ba, Jimmy and Tran, Dustin and Grosse, Roger},
	month = apr,
	year = {2018},
	note = {Number: arXiv:1803.04386
arXiv:1803.04386 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:/home/harnist/Zotero/storage/DF573ZIF/Wen et al. - 2018 - Flipout Efficient Pseudo-Independent Weight Pertu.pdf:application/pdf;arXiv.org Snapshot:/home/harnist/Zotero/storage/NYV22LMI/1803.html:text/html},
}

@misc{noauthor_svi_nodate,
	title = {{SVI} {Part} {IV}: {Tips} and {Tricks} - {Pyro} {Tutorials} 1.8.1 documentation},
	url = {https://pyro.ai/examples/svi_part_iv.html},
	urldate = {2022-06-27},
}

@article{bauer_quiet_2015,
	title = {The quiet revolution of numerical weather prediction},
	volume = {525},
	issn = {0028-0836, 1476-4687},
	url = {http://www.nature.com/articles/nature14956},
	doi = {10.1038/nature14956},
	language = {en},
	number = {7567},
	urldate = {2022-07-01},
	journal = {Nature},
	author = {Bauer, Peter and Thorpe, Alan and Brunet, Gilbert},
	month = sep,
	year = {2015},
	pages = {47--55},
	file = {Bauer et al. - 2015 - The quiet revolution of numerical weather predicti.pdf:/home/harnist/Zotero/storage/9I8FYVJ4/Bauer et al. - 2015 - The quiet revolution of numerical weather predicti.pdf:application/pdf},
}

@article{rinehart_three-dimensional_1978,
	title = {Three-dimensional storm motion detection by conventional weather radar},
	volume = {273},
	copyright = {1978 Nature Publishing Group},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/273287a0},
	doi = {10.1038/273287a0},
	abstract = {KNOWLEDGE of the kinematic structure of storms is important for understanding the internal physical processes. Radar has long provided information on the three-dimensional structure of storms from measurements of the radar reflectivity factor alone. Early users of radar gave total storm movement only, whereas later radar data were used to reveal internal motions based on information related to cloud physics such as the three-dimensional morphology of the storm volume. Such approaches have continued by using the increasingly finer scale details provided by more modern radar systems. Both Barge and Bergwall2 and Browning and Foote3 have used fine scale reflectivity structure to determine airflow in hailstorms. Doppler radar added a new dimension to our capabilities through its ability to measure directly the radial component of motion of an ensemble of hydrometeor particles. Two4 or three5 Doppler radars collecting data in conjunction, the equation of mass continuity, and an empirical radar reflectivity–terminal velocity relationship have enabled the estimation of the full three-dimensional airflow fields in parts of storms. Because of the inherent advantage of Doppler radar in motion detection, little effort has been directed toward developing objective schemes of determining internal storm motions with conventional meteorological radars. Pattern recognition schemes using correlation coefficient techniques6, Fourier analysis7, and gaussian curve fitting8 have been used with radar and satellite data, but primarily for detecting overall storm motions, echo merging and echo splitting. Here we describe an objective use of radar reflectivity factor data from a single conventional weather radar to give information related to the three-dimensional motions within a storm.},
	language = {en},
	number = {5660},
	urldate = {2022-07-01},
	journal = {Nature},
	author = {Rinehart, R. E. and Garvey, E. T.},
	month = may,
	year = {1978},
	note = {Number: 5660
Publisher: Nature Publishing Group},
	keywords = {Humanities and Social Sciences, multidisciplinary, Science},
	pages = {287--289},
	file = {Snapshot:/home/harnist/Zotero/storage/76NZ2XTD/273287a0.html:text/html},
}

@misc{shi_deep_2017,
	title = {Deep {Learning} for {Precipitation} {Nowcasting}: {A} {Benchmark} and {A} {New} {Model}},
	shorttitle = {Deep {Learning} for {Precipitation} {Nowcasting}},
	url = {http://arxiv.org/abs/1706.03458},
	abstract = {With the goal of making high-resolution forecasts of regional rainfall, precipitation nowcasting has become an important and fundamental technology underlying various public services ranging from rainstorm warnings to ﬂight safety. Recently, the Convolutional LSTM (ConvLSTM) model has been shown to outperform traditional optical ﬂow based methods for precipitation nowcasting, suggesting that deep learning models have a huge potential for solving the problem. However, the convolutional recurrence structure in ConvLSTM-based models is location-invariant while natural motion and transformation (e.g., rotation) are location-variant in general. Furthermore, since deep-learning-based precipitation nowcasting is a newly emerging area, clear evaluation protocols have not yet been established. To address these problems, we propose both a new model and a benchmark for precipitation nowcasting. Speciﬁcally, we go beyond ConvLSTM and propose the Trajectory GRU (TrajGRU) model that can actively learn the location-variant structure for recurrent connections. Besides, we provide a benchmark that includes a real-world large-scale dataset from the Hong Kong Observatory, a new training loss, and a comprehensive evaluation protocol to facilitate future research and gauge the state of the art.},
	language = {en},
	urldate = {2022-07-01},
	publisher = {arXiv},
	author = {Shi, Xingjian and Gao, Zhihan and Lausen, Leonard and Wang, Hao and Yeung, Dit-Yan and Wong, Wai-kin and Woo, Wang-chun},
	month = oct,
	year = {2017},
	note = {arXiv:1706.03458 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {Shi et al. - 2017 - Deep Learning for Precipitation Nowcasting A Benc.pdf:/home/harnist/Zotero/storage/2QTNGF3E/Shi et al. - 2017 - Deep Learning for Precipitation Nowcasting A Benc.pdf:application/pdf},
}

@misc{shi_convolutional_2015,
	title = {Convolutional {LSTM} {Network}: {A} {Machine} {Learning} {Approach} for {Precipitation} {Nowcasting}},
	shorttitle = {Convolutional {LSTM} {Network}},
	url = {http://arxiv.org/abs/1506.04214},
	doi = {10.48550/arXiv.1506.04214},
	abstract = {The goal of precipitation nowcasting is to predict the future rainfall intensity in a local region over a relatively short period of time. Very few previous studies have examined this crucial and challenging weather forecasting problem from the machine learning perspective. In this paper, we formulate precipitation nowcasting as a spatiotemporal sequence forecasting problem in which both the input and the prediction target are spatiotemporal sequences. By extending the fully connected LSTM (FC-LSTM) to have convolutional structures in both the input-to-state and state-to-state transitions, we propose the convolutional LSTM (ConvLSTM) and use it to build an end-to-end trainable model for the precipitation nowcasting problem. Experiments show that our ConvLSTM network captures spatiotemporal correlations better and consistently outperforms FC-LSTM and the state-of-the-art operational ROVER algorithm for precipitation nowcasting.},
	urldate = {2022-07-01},
	publisher = {arXiv},
	author = {Shi, Xingjian and Chen, Zhourong and Wang, Hao and Yeung, Dit-Yan and Wong, Wai-kin and Woo, Wang-chun},
	month = sep,
	year = {2015},
	note = {arXiv:1506.04214 [cs]
version: 2},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:/home/harnist/Zotero/storage/V6YZ7Z9M/Shi et al. - 2015 - Convolutional LSTM Network A Machine Learning App.pdf:application/pdf;arXiv.org Snapshot:/home/harnist/Zotero/storage/QEKUKQR4/1506.html:text/html},
}

@article{seed_formulation_2013,
	title = {Formulation and evaluation of a scale decomposition-based stochastic precipitation nowcast scheme},
	volume = {49},
	issn = {1944-7973},
	url = {http://onlinelibrary.wiley.com/doi/abs/10.1002/wrcr.20536},
	doi = {10.1002/wrcr.20536},
	abstract = {There are significant uncertainties inherent in precipitation forecasts and these uncertainties can be communicated to users via large ensembles that are generated using stochastic models of forecast error. The Met Office and the Australian Bureau of Meteorology developed the Short Term Ensemble Prediction System (STEPS) was developed to address these user requirements and has been operational for a number of years. The initial formulation of Bowler et al. (2006) has been revised and extended to improve the performance over large domains, to include radar observation errors, and to facilitate the combination of forecasts from a number of sources. This paper reviews the formulation of STEPS, discusses those aspects of the formulation that have proved most problematic and presents some solutions. The performance of STEPS nowcasts is evaluated using a combination of case study examples and statistical verification from the UK. Routine forecast verification demonstrates that STEPS is capable of producing near optimal blends of a rainfall nowcast and high resolution NWP forecast. It also shows that the spread of STEPS nowcast ensembles are a good predictor of the error in the control member (unperturbed) nowcast.},
	language = {en},
	number = {10},
	urldate = {2022-07-02},
	journal = {Water Resources Research},
	author = {Seed, Alan W. and Pierce, Clive E. and Norman, Katie},
	year = {2013},
	note = {\_eprint: https://agupubs.onlinelibrary.wiley.com/doi/pdf/10.1002/wrcr.20536},
	keywords = {rainfall, nowcast, uncertainty},
	pages = {6624--6641},
	file = {Full Text PDF:/home/harnist/Zotero/storage/I5G57QTA/Seed et al. - 2013 - Formulation and evaluation of a scale decompositio.pdf:application/pdf;Snapshot:/home/harnist/Zotero/storage/BCBZN6Q7/wrcr.html:text/html},
}

@article{leinonen_climatology_2012,
	title = {A {Climatology} of {Disdrometer} {Measurements} of {Rainfall} in {Finland} over {Five} {Years} with {Implications} for {Global} {Radar} {Observations}},
	copyright = {info:eu-repo/semantics/openAccess},
	url = {https://helda.helsinki.fi/handle/10138/36973},
	abstract = {To improve the understanding of high-latitude rain microphysics and its implications for the remote sensing of rainfall by ground-based and spaceborne radars, raindrop size measurements have been analyzed that were collected over five years with a Joss–Waldvogel disdrometer located in Järvenpää, Finland. The analysis shows that the regional climate is characterized by light rain and small drop size with narrow size distributions and that the mutual relations of drop size distribution parameters differ from those reported at lower latitudes. Radar parameters computed from the distributions demonstrate that the high latitudes are a challenging target for weather radar observations, particularly those employing polarimetric and dual-frequency techniques. Nevertheless, the findings imply that polarimetric ground radars can produce reliable “ground truth” estimates for space observations and identify dual-frequency radars utilizing a W-band channel as promising tools for observing rainfall in the high-latitude climate.},
	language = {eng},
	urldate = {2022-07-02},
	author = {Leinonen, Jussi and Moisseev, Dmitri and Leskinen, Matti and Petersen, Walter A.},
	year = {2012},
	note = {Accepted: 2012-09-30T22:50:46Z},
	file = {Full Text PDF:/home/harnist/Zotero/storage/85NA85GV/Leinonen et al. - 2012 - A Climatology of Disdrometer Measurements of Rainf.pdf:application/pdf;Snapshot:/home/harnist/Zotero/storage/HG32YS5G/36973.html:text/html},
}

@book{fabry_radar_2018,
	title = {Radar {Meteorology}: {Principles} and {Practice}},
	isbn = {978-1-316-29947-0},
	shorttitle = {Radar {Meteorology}},
	abstract = {This practical textbook introduces the fundamental physics behind radar measurements, to guide students and practitioners in the proper interpretation of radar reflectivity, Doppler velocity and dual-polarization imagery. Operational applications are explored, such as how radar imagery can be used to analyze and forecast convective and widespread weather systems. The book concludes with an overview of current research topics, including the study of clouds and precipitation using radars, signal processing, and data assimilation. Numerous full-color illustrations are included, as well as problem sets, case studies, and a variety of supplementary electronic material including animated time sequences of images to help convey complex concepts. This book is a valuable resource for advanced undergraduate and graduate students in radar meteorology and other related courses, such as precipitation microphysics and dynamics. It will also make a useful reference for researchers, professional meteorologists and hydrologists.},
	language = {en},
	publisher = {Cambridge University Press},
	author = {Fabry, Frédéric},
	month = mar,
	year = {2018},
	note = {Google-Books-ID: 0aRwCQAAQBAJ},
	keywords = {Science / Earth Sciences / Hydrology, Science / Earth Sciences / Meteorology \& Climatology, Science / Physics / General},
}

@misc{noauthor_next_2020,
	title = {Next {Generation} {Weather} {Radar} ({NEXRAD})},
	url = {http://www.ncei.noaa.gov/products/radar/next-generation-weather-radar},
	abstract = {The Next Generation Weather Radar (NEXRAD) system is a network of 160 high-resolution S-band Doppler weather radars jointly operated by the National Weather Service (NWS), the Federal Aviation Administration (FAA), and the U.S. Air Force. The NEXRAD system detects precipitation and wind, and its data can be processed to map precipitation patterns and movement. NCEI provides access to archived NEXRAD Level-II data and Level-III products.},
	language = {en},
	urldate = {2022-07-02},
	journal = {National Centers for Environmental Information (NCEI)},
	month = sep,
	year = {2020},
}

@article{saltikoff_opera_2019,
	title = {{OPERA} the {Radar} {Project}},
	volume = {10},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2073-4433},
	url = {https://www.mdpi.com/2073-4433/10/6/320},
	doi = {10.3390/atmos10060320},
	abstract = {The Operational Program on the Exchange of Weather Radar Information (OPERA) has co-ordinated radar co-operation among national weather services in Europe for more than 20 years. It has introduced its own, manufacturer-independent data model, runs its own data center, and produces Pan-European radar composites. The applications using this data vary from data assimilation to flood warnings and the monitoring of animal migration. It has used several approaches to provide a homogeneous combination of disparate raw data and to indicate the reliability of its products. In particular, if a pixel shows no precipitation, it is important to know if that pixel is dry or if the measurement was missing.},
	language = {en},
	number = {6},
	urldate = {2022-07-02},
	journal = {Atmosphere},
	author = {Saltikoff, Elena and Haase, Günther and Delobbe, Laurent and Gaussiat, Nicolas and Martet, Maud and Idziorek, Daniel and Leijnse, Hidde and Novák, Petr and Lukach, Maryna and Stephan, Klaus},
	month = jun,
	year = {2019},
	note = {Number: 6
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {precipitation, international co-operation, quality control, weather radars},
	pages = {320},
	file = {Full Text PDF:/home/harnist/Zotero/storage/V62FU7AA/Saltikoff et al. - 2019 - OPERA the Radar Project.pdf:application/pdf;Snapshot:/home/harnist/Zotero/storage/YNCTD8AN/htm.html:text/html},
}

@inproceedings{cao_measurement_2016,
	title = {Measurement uncertainty and system assessment of weather radar network in {Germany}},
	doi = {10.1109/RADAR.2016.7485284},
	abstract = {The Deutscher Wetterdienst (D WD) weather radar network has been upgraded with new C-band Polarimetrie radar systems. The current study presents the results of a field research campaign, which was designed to assess the radar systems through analyzing radar measurements. A novel point mode approach proposed recently by Enterprise Electronics Corporation (EEC) was used for the data collection and analysis. Results show that DWD weather radars generally have a high system quality and contribute a negligible uncertainty to the radar measurements, as compared to the uncertainty caused by the sampling effect. The proposed point mode approach is validated with DWD radar data analysis and highly recommended as quality measure for commercial weather radars.},
	booktitle = {2016 {IEEE} {Radar} {Conference} ({RadarConf})},
	author = {Cao, Qing and Knight, Michael and Frech, Michael and Mammen, Theodor},
	month = may,
	year = {2016},
	note = {ISSN: 2375-5318},
	keywords = {Radar measurements, Meteorological radar, Meteorology, Measurement errors, polarimetric weather radar, Radar antennas, Radar polarimetry, system assessment},
	pages = {1--5},
	file = {IEEE Xplore Abstract Record:/home/harnist/Zotero/storage/T79R7N87/7485284.html:text/html;IEEE Xplore Full Text PDF:/home/harnist/Zotero/storage/ZKEAFQ3M/Cao et al. - 2016 - Measurement uncertainty and system assessment of w.pdf:application/pdf},
}

@article{kiureghian_aleatory_2009,
	series = {Risk {Acceptance} and {Risk} {Communication}},
	title = {Aleatory or epistemic? {Does} it matter?},
	volume = {31},
	issn = {0167-4730},
	shorttitle = {Aleatory or epistemic?},
	url = {https://www.sciencedirect.com/science/article/pii/S0167473008000556},
	doi = {10.1016/j.strusafe.2008.06.020},
	abstract = {The sources and characters of uncertainties in engineering modeling for risk and reliability analyses are discussed. While many sources of uncertainty may exist, they are generally categorized as either aleatory or epistemic. Uncertainties are characterized as epistemic, if the modeler sees a possibility to reduce them by gathering more data or by refining models. Uncertainties are categorized as aleatory if the modeler does not foresee the possibility of reducing them. From a pragmatic standpoint, it is useful to thus categorize the uncertainties within a model, since it then becomes clear as to which uncertainties have the potential of being reduced. More importantly, epistemic uncertainties may introduce dependence among random events, which may not be properly noted if the character of uncertainties is not correctly modeled. Influences of the two types of uncertainties in reliability assessment, codified design, performance-based engineering and risk-based decision-making are discussed. Two simple examples demonstrate the influence of statistical dependence arising from epistemic uncertainties on systems and time-variant reliability problems.},
	language = {en},
	number = {2},
	urldate = {2022-07-04},
	journal = {Structural Safety},
	author = {Kiureghian, Armen Der and Ditlevsen, Ove},
	month = mar,
	year = {2009},
	keywords = {Predictive models, Uncertainty, Aleatory, Epistemic, Ergodicity, Parameter uncertainty, Probability distribution choice, Statistical dependence, Systems, Time-variant reliability},
	pages = {105--112},
	file = {ScienceDirect Full Text PDF:/home/harnist/Zotero/storage/3DKGS99L/Kiureghian and Ditlevsen - 2009 - Aleatory or epistemic Does it matter.pdf:application/pdf;ScienceDirect Snapshot:/home/harnist/Zotero/storage/5H3EQUKQ/S0167473008000556.html:text/html},
}

@misc{oh_action-conditional_2015,
	title = {Action-{Conditional} {Video} {Prediction} using {Deep} {Networks} in {Atari} {Games}},
	url = {http://arxiv.org/abs/1507.08750},
	doi = {10.48550/arXiv.1507.08750},
	abstract = {Motivated by vision-based reinforcement learning (RL) problems, in particular Atari games from the recent benchmark Aracade Learning Environment (ALE), we consider spatio-temporal prediction problems where future (image-)frames are dependent on control variables or actions as well as previous frames. While not composed of natural scenes, frames in Atari games are high-dimensional in size, can involve tens of objects with one or more objects being controlled by the actions directly and many other objects being influenced indirectly, can involve entry and departure of objects, and can involve deep partial observability. We propose and evaluate two deep neural network architectures that consist of encoding, action-conditional transformation, and decoding layers based on convolutional neural networks and recurrent neural networks. Experimental results show that the proposed architectures are able to generate visually-realistic frames that are also useful for control over approximately 100-step action-conditional futures in some games. To the best of our knowledge, this paper is the first to make and evaluate long-term predictions on high-dimensional video conditioned by control inputs.},
	urldate = {2022-07-04},
	publisher = {arXiv},
	author = {Oh, Junhyuk and Guo, Xiaoxiao and Lee, Honglak and Lewis, Richard and Singh, Satinder},
	month = dec,
	year = {2015},
	note = {arXiv:1507.08750 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
	file = {arXiv Fulltext PDF:/home/harnist/Zotero/storage/KUHNRIK3/Oh et al. - 2015 - Action-Conditional Video Prediction using Deep Net.pdf:application/pdf;arXiv.org Snapshot:/home/harnist/Zotero/storage/DMZZ89DG/1507.html:text/html},
}

@misc{agrawal_machine_2019,
	title = {Machine {Learning} for {Precipitation} {Nowcasting} from {Radar} {Images}},
	url = {http://arxiv.org/abs/1912.12132},
	doi = {10.48550/arXiv.1912.12132},
	abstract = {High-resolution nowcasting is an essential tool needed for effective adaptation to climate change, particularly for extreme weather. As Deep Learning (DL) techniques have shown dramatic promise in many domains, including the geosciences, we present an application of DL to the problem of precipitation nowcasting, i.e., high-resolution (1 km x 1 km) short-term (1 hour) predictions of precipitation. We treat forecasting as an image-to-image translation problem and leverage the power of the ubiquitous UNET convolutional neural network. We find this performs favorably when compared to three commonly used models: optical flow, persistence and NOAA's numerical one-hour HRRR nowcasting prediction.},
	urldate = {2022-07-04},
	publisher = {arXiv},
	author = {Agrawal, Shreya and Barrington, Luke and Bromberg, Carla and Burge, John and Gazen, Cenk and Hickey, Jason},
	month = dec,
	year = {2019},
	note = {arXiv:1912.12132 [cs, stat]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:/home/harnist/Zotero/storage/M55826RD/Agrawal et al. - 2019 - Machine Learning for Precipitation Nowcasting from.pdf:application/pdf;arXiv.org Snapshot:/home/harnist/Zotero/storage/RUAM4XZJ/1912.html:text/html},
}

@misc{sonderby_metnet_2020,
	title = {{MetNet}: {A} {Neural} {Weather} {Model} for {Precipitation} {Forecasting}},
	shorttitle = {{MetNet}},
	url = {http://arxiv.org/abs/2003.12140},
	doi = {10.48550/arXiv.2003.12140},
	abstract = {Weather forecasting is a long standing scientific challenge with direct social and economic impact. The task is suitable for deep neural networks due to vast amounts of continuously collected data and a rich spatial and temporal structure that presents long range dependencies. We introduce MetNet, a neural network that forecasts precipitation up to 8 hours into the future at the high spatial resolution of 1 km\${\textasciicircum}2\$ and at the temporal resolution of 2 minutes with a latency in the order of seconds. MetNet takes as input radar and satellite data and forecast lead time and produces a probabilistic precipitation map. The architecture uses axial self-attention to aggregate the global context from a large input patch corresponding to a million square kilometers. We evaluate the performance of MetNet at various precipitation thresholds and find that MetNet outperforms Numerical Weather Prediction at forecasts of up to 7 to 8 hours on the scale of the continental United States.},
	urldate = {2022-07-05},
	publisher = {arXiv},
	author = {Sønderby, Casper Kaae and Espeholt, Lasse and Heek, Jonathan and Dehghani, Mostafa and Oliver, Avital and Salimans, Tim and Agrawal, Shreya and Hickey, Jason and Kalchbrenner, Nal},
	month = mar,
	year = {2020},
	note = {arXiv:2003.12140 [physics, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Physics - Atmospheric and Oceanic Physics},
	file = {arXiv Fulltext PDF:/home/harnist/Zotero/storage/4YBSW7CK/Sønderby et al. - 2020 - MetNet A Neural Weather Model for Precipitation F.pdf:application/pdf;arXiv.org Snapshot:/home/harnist/Zotero/storage/QMDE2GF9/2003.html:text/html},
}

@misc{ho_axial_2019,
	title = {Axial {Attention} in {Multidimensional} {Transformers}},
	url = {http://arxiv.org/abs/1912.12180},
	doi = {10.48550/arXiv.1912.12180},
	abstract = {We propose Axial Transformers, a self-attention-based autoregressive model for images and other data organized as high dimensional tensors. Existing autoregressive models either suffer from excessively large computational resource requirements for high dimensional data, or make compromises in terms of distribution expressiveness or ease of implementation in order to decrease resource requirements. Our architecture, by contrast, maintains both full expressiveness over joint distributions over data and ease of implementation with standard deep learning frameworks, while requiring reasonable memory and computation and achieving state-of-the-art results on standard generative modeling benchmarks. Our models are based on axial attention, a simple generalization of self-attention that naturally aligns with the multiple dimensions of the tensors in both the encoding and the decoding settings. Notably the proposed structure of the layers allows for the vast majority of the context to be computed in parallel during decoding without introducing any independence assumptions. This semi-parallel structure goes a long way to making decoding from even a very large Axial Transformer broadly applicable. We demonstrate state-of-the-art results for the Axial Transformer on the ImageNet-32 and ImageNet-64 image benchmarks as well as on the BAIR Robotic Pushing video benchmark. We open source the implementation of Axial Transformers.},
	urldate = {2022-07-05},
	publisher = {arXiv},
	author = {Ho, Jonathan and Kalchbrenner, Nal and Weissenborn, Dirk and Salimans, Tim},
	month = dec,
	year = {2019},
	note = {arXiv:1912.12180 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:/home/harnist/Zotero/storage/66FEJQ9P/Ho et al. - 2019 - Axial Attention in Multidimensional Transformers.pdf:application/pdf;arXiv.org Snapshot:/home/harnist/Zotero/storage/FLMFBUQW/1912.html:text/html},
}

@inproceedings{denker_transforming_1990,
	title = {Transforming {Neural}-{Net} {Output} {Levels} to {Probability} {Distributions}},
	volume = {3},
	url = {https://proceedings.neurips.cc/paper/1990/hash/7eacb532570ff6858afd2723755ff790-Abstract.html},
	abstract = {(1)  The  outputs  of a  typical  multi-output  classification  network  do  not  satisfy the axioms of probability; probabilities should be positive and sum  to one.  This problem  can  be solved  by  treating  the trained  network  as  a  preprocessor that produces  a  feature  vector that can be further  processed,  for instance by classical statistical estimation techniques.  (2) We present a  method for computing the first two moments ofthe probability distribution  indicating the range of outputs that are  consistent  with the input and the  training  data.  It is  particularly  useful  to  combine  these  two  ideas:  we  implement the  ideas  of section  1 using  Parzen  windows,  where  the  shape  and relative size  of each  window  is  computed  using the ideas of section  2.  This  allows  us  to make  contact  between  important  theoretical ideas  (e.g.  the  ensemble  formalism)  and  practical  techniques  (e.g.  back-prop).  Our  results  also  shed  new  light  on  and  generalize  the  well-known  "soft max"  scheme.},
	urldate = {2022-07-05},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Morgan-Kaufmann},
	author = {Denker, John and LeCun, Yann},
	year = {1990},
	file = {Full Text PDF:/home/harnist/Zotero/storage/PFAINVAD/Denker and LeCun - 1990 - Transforming Neural-Net Output Levels to Probabili.pdf:application/pdf},
}

@inproceedings{tishby_consistent_1989,
	title = {Consistent inference of probabilities in layered networks: predictions and generalizations},
	shorttitle = {Consistent inference of probabilities in layered networks},
	doi = {10.1109/IJCNN.1989.118274},
	abstract = {The problem of learning a general input-output relation using a layered neural network is discussed in a statistical framework. By imposing the consistency condition that the error minimization be equivalent to a likelihood maximization for training the network, the authors arrive at a Gibbs distribution on a canonical ensemble of networks with the same architecture. This statistical description enables them to evaluate the probability of a correct prediction of an independent example, after training the network on a given training set. The prediction probability is highly correlated with the generalization ability of the network, as measured outside the training set. This suggests a general and practical criterion for training layered networks by minimizing prediction errors. The authors demonstrate the utility of this criterion for selecting the optimal architecture in the continuity problem. As a theoretical application of the statistical formalism, they discuss the question of learning curves and estimate the sufficient training size needed for correct generalization, in a simple example.{\textless}{\textgreater}},
	booktitle = {International 1989 {Joint} {Conference} on {Neural} {Networks}},
	author = {{Tishby} and {Levin} and {Solla}},
	year = {1989},
	keywords = {Neural networks, Probability, Learning systems},
	pages = {403--409 vol.2},
	file = {IEEE Xplore Abstract Record:/home/harnist/Zotero/storage/QA6BSJAB/118274.html:text/html;IEEE Xplore Full Text PDF:/home/harnist/Zotero/storage/SHA3KHIN/Tishby et al. - 1989 - Consistent inference of probabilities in layered n.pdf:application/pdf},
}

@inproceedings{gal_dropout_2016,
	title = {Dropout as a {Bayesian} {Approximation}: {Representing} {Model} {Uncertainty} in {Deep} {Learning}},
	shorttitle = {Dropout as a {Bayesian} {Approximation}},
	url = {https://proceedings.mlr.press/v48/gal16.html},
	abstract = {Deep learning tools have gained tremendous attention in applied machine learning. However such tools for regression and classification do not capture model uncertainty. In comparison, Bayesian models offer a mathematically grounded framework to reason about model uncertainty, but usually come with a prohibitive computational cost. In this paper we develop a new theoretical framework casting dropout training in deep neural networks (NNs) as approximate Bayesian inference in deep Gaussian processes. A direct result of this theory gives us tools to model uncertainty with dropout NNs – extracting information from existing models that has been thrown away so far. This mitigates the problem of representing uncertainty in deep learning without sacrificing either computational complexity or test accuracy. We perform an extensive study of the properties of dropout’s uncertainty. Various network architectures and non-linearities are assessed on tasks of regression and classification, using MNIST as an example. We show a considerable improvement in predictive log-likelihood and RMSE compared to existing state-of-the-art methods, and finish by using dropout’s uncertainty in deep reinforcement learning.},
	language = {en},
	urldate = {2022-07-05},
	booktitle = {Proceedings of {The} 33rd {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Gal, Yarin and Ghahramani, Zoubin},
	month = jun,
	year = {2016},
	note = {ISSN: 1938-7228},
	pages = {1050--1059},
	file = {Full Text PDF:/home/harnist/Zotero/storage/QQ6CPXY6/Gal and Ghahramani - 2016 - Dropout as a Bayesian Approximation Representing .pdf:application/pdf},
}

@article{rinehart_three-dimensional_1978-1,
	title = {Three-dimensional storm motion detection by conventional weather radar},
	volume = {273},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/273287a0},
	doi = {10.1038/273287a0},
	abstract = {KNOWLEDGE of the kinematic structure of storms is important for understanding the internal physical processes. Radar has long provided information on the three-dimensional structure of storms from measurements of the radar reflectivity factor alone. Early users of radar gave total storm movement only, whereas later radar data were used to reveal internal motions based on information related to cloud physics such as the three-dimensional morphology of the storm volume. Such approaches have continued by using the increasingly finer scale details provided by more modern radar systems. Both Barge and Bergwall2 and Browning and Foote3 have used fine scale reflectivity structure to determine airflow in hailstorms. Doppler radar added a new dimension to our capabilities through its ability to measure directly the radial component of motion of an ensemble of hydrometeor particles. Two4 or three5 Doppler radars collecting data in conjunction, the equation of mass continuity, and an empirical radar reflectivity–terminal velocity relationship have enabled the estimation of the full three-dimensional airflow fields in parts of storms. Because of the inherent advantage of Doppler radar in motion detection, little effort has been directed toward developing objective schemes of determining internal storm motions with conventional meteorological radars. Pattern recognition schemes using correlation coefficient techniques6, Fourier analysis7, and gaussian curve fitting8 have been used with radar and satellite data, but primarily for detecting overall storm motions, echo merging and echo splitting. Here we describe an objective use of radar reflectivity factor data from a single conventional weather radar to give information related to the three-dimensional motions within a storm.},
	language = {en},
	number = {5660},
	urldate = {2022-07-05},
	journal = {Nature},
	author = {Rinehart, R. E. and Garvey, E. T.},
	month = may,
	year = {1978},
	note = {Number: 5660
Publisher: Nature Publishing Group},
	keywords = {Humanities and Social Sciences, multidisciplinary, Science},
	pages = {287--289},
	file = {Full Text PDF:/home/harnist/Zotero/storage/QTFTQG96/Rinehart and Garvey - 1978 - Three-dimensional storm motion detection by conven.pdf:application/pdf},
}

@article{seed_dynamic_2003,
	title = {A {Dynamic} and {Spatial} {Scaling} {Approach} to {Advection} {Forecasting}},
	volume = {42},
	issn = {1520-0450, 0894-8763},
	url = {https://journals.ametsoc.org/view/journals/apme/42/3/1520-0450_2003_042_0381_adassa_2.0.co_2.xml},
	doi = {10.1175/1520-0450(2003)042<0381:ADASSA>2.0.CO;2},
	abstract = {Abstract Quantitative nowcasts of rainfall are frequently based on the advection of rain fields observed by weather radar. Spectral Prognosis (S-PROG) is an advection-based nowcasting system that uses the observations that rain fields commonly exhibit both spatial and dynamic scaling properties, that is, the lifetime of a feature in the field is dependent on the scale of the feature (large features evolve more slowly than small features), and that features at all scales between the outer and inner observed scales are present in the field. The logarithm of the radar reflectivity field is disaggregated into a set or cascade of fields, in which each field in the set (or level in the cascade) represents the features of the original field over a limited range of scales. The Lagrangian temporal evolution of each level in the cascade is modeled using a simple autoregressive (lag 2) model, which automatically causes the forecast field to become smooth as the structures at the various scales evolve through their life cycles, or can be used to generate conditional simulations if the noise term is included. This paper describes the model and presents preliminary results.},
	language = {EN},
	number = {3},
	urldate = {2022-07-05},
	journal = {Journal of Applied Meteorology and Climatology},
	author = {Seed, A. W.},
	month = mar,
	year = {2003},
	note = {Publisher: American Meteorological Society
Section: Journal of Applied Meteorology and Climatology},
	pages = {381--388},
	file = {Full Text PDF:/home/harnist/Zotero/storage/BW935RJN/Seed - 2003 - A Dynamic and Spatial Scaling Approach to Advectio.pdf:application/pdf;Snapshot:/home/harnist/Zotero/storage/5N8NX36A/1520-0450_2003_042_0381_adassa_2.0.co_2.html:text/html},
}

@article{pulkkinen_nowcasting_2020,
	title = {Nowcasting of {Convective} {Rainfall} {Using} {Volumetric} {Radar} {Observations}},
	volume = {58},
	issn = {1558-0644},
	doi = {10.1109/TGRS.2020.2984594},
	abstract = {Short-range forecasts (nowcasts) of rainfall facilitate providing early warning of severe rainfall and flooding, which is particularly important in densely populated urban areas. Nowcasts are conventionally obtained by the extrapolation of radar echoes from a constant altitude plan position indicator (CAPPI) or lowest-angle plan position indicator (PPI). Lacking a model for growth or decay, this approach has a limited ability to forecast the summertime convective storms. In a previous attempt to address this shortcoming, called RadVil, the predicted surface rain rate is obtained from mass balance equations of vertically integrated liquid (VIL) retrieved from volumetric reflectivity measurements. Predicting the growth and decay has also been attempted by using an autoregressive (AR) model, which led to the development of spectral prognosis (S-PROG). A novel combination of these two methodologies, called ANVIL, is proposed. In this approach, the growth and decay of VIL are modeled by an autoregressive integrated (ARI) process. It is shown that the predictability of growth and decay is scale-dependent. Thus, the key idea of ANVIL is to decompose the VIL into multiple spatial scales and apply a separate ARI model to each scale. The operational feasibility of ANVIL is evaluated using the Next-Generation Radar (NEXRAD)/WSR-88D radar that covers the Dallas-Fort Worth metropolitan area. The evaluation is done using ten convective events in 2018 and 2019. Using several verification metrics, it is shown that ANVIL has up to 25\% improved skill compared to conventional nowcasting techniques. The improvement is consistent for a wide range of spatial scales (1-11 km) and rain rate thresholds (5-20 mmh-1).},
	number = {11},
	journal = {IEEE Transactions on Geoscience and Remote Sensing},
	author = {Pulkkinen, Seppo and Chandrasekar, V. and von Lerber, Annakaisa and Harri, Ari-Matti},
	month = nov,
	year = {2020},
	note = {Conference Name: IEEE Transactions on Geoscience and Remote Sensing},
	keywords = {forecasting, Atmosphere, autoregressive (AR) processes, Computational modeling, Mathematical model, meteorology, Predictive models, radar applications, Radar measurements, Rain, spatiotemporal phenomena, urban areas},
	pages = {7845--7859},
	file = {IEEE Xplore Full Text PDF:/home/harnist/Zotero/storage/8DWLSNG9/Pulkkinen et al. - 2020 - Nowcasting of Convective Rainfall Using Volumetric.pdf:application/pdf},
}

@article{andersson_model_1991,
	title = {A {Model} for {Probability} {Nowcasts} of {Accumulated} {Precipitation} {Using} {Radar}},
	volume = {30},
	issn = {1520-0450, 0894-8763},
	url = {https://journals.ametsoc.org/view/journals/apme/30/1/1520-0450_1991_030_0135_amfpno_2_0_co_2.xml},
	doi = {10.1175/1520-0450(1991)030<0135:AMFPNO>2.0.CO;2},
	abstract = {Abstract A new model for making probability forecasts of accumulated spot precipitation from weather radar data is presented. The model selects a source region upwind of the forecast spot. All pixels (horizontal size 2 × 2 km2) within the source region are considered, having the same probability of hitting the forecast-spot. A pixel hitting the forecast spot is supposed to precipitate there a short time (about 10 min.). A drawing is performed, and a frequency distribution of accumulated precipitation during the first time step of the forecast is obtained. A second drawing gives the frequency distribution of accumulated precipitation during the first to second time step, a third one during the first to third, and so on until the end of the forecast period is reached. A number of forecasts for 1-h accumulated precipitation, with lead times of 0, 1, and 2 h, have been performed and verified. The forecasts for 0-h lead time got the highest Brier skill scores, +50\% to 60\% relative to climatological forecasts for accumulated precipitation below 1 mm.},
	language = {EN},
	number = {1},
	urldate = {2022-07-05},
	journal = {Journal of Applied Meteorology and Climatology},
	author = {Andersson, Tage and Ivarsson, Karl-Ivar},
	month = jan,
	year = {1991},
	note = {Publisher: American Meteorological Society
Section: Journal of Applied Meteorology and Climatology},
	pages = {135--141},
	file = {Full Text PDF:/home/harnist/Zotero/storage/TZ69F8WS/Andersson and Ivarsson - 1991 - A Model for Probability Nowcasts of Accumulated Pr.pdf:application/pdf;Snapshot:/home/harnist/Zotero/storage/CMX9D5WL/1520-0450_1991_030_0135_amfpno_2_0_co_2.html:text/html},
}

@article{germann_scale_2004,
	title = {Scale {Dependence} of the {Predictability} of {Precipitation} from {Continental} {Radar} {Images}. {Part} {II}: {Probability} {Forecasts}},
	volume = {43},
	issn = {1520-0450, 0894-8763},
	shorttitle = {Scale {Dependence} of the {Predictability} of {Precipitation} from {Continental} {Radar} {Images}. {Part} {II}},
	url = {https://journals.ametsoc.org/view/journals/apme/43/1/1520-0450_2004_043_0074_sdotpo_2.0.co_2.xml},
	doi = {10.1175/1520-0450(2004)043<0074:SDOTPO>2.0.CO;2},
	abstract = {Abstract Eulerian and Lagrangian persistence of precipitation patterns derived from continental-scale radar composite images are used as a measure of predictability and for nowcasting [the McGill algorithm for precipitation nowcasting by Lagrangian extrapolation (MAPLE)]. A previous paper introduced the method and focused on the lifetime of patterns of rainfall rates and the scale dependence of predictability. This paper shows how the method of persistence of radar precipitation patterns can be extended to produce probabilistic forecasts. For many applications, probabilistic information is at least as important as the expected point value. Four techniques are presented and compared. One is entirely new and makes use of the intrinsic relationship between scale and predictability. The results with this technique suggest potential use for downscaling of numerical model output. For the 143 h of precipitation analyzed so far, roughly a factor of 2 was obtained between lead times of Eulerian and Lagrangian techniques. Three of the four techniques involve a scale parameter. The slope of the relationship between optimum scale and lead time is about 1 and 2 km min−1 for Lagrangian and Eulerian techniques, respectively. The skill scores obtained for the four techniques can be used as a measure of predictability in terms of probabilistic rainfall rates. The progress of other probabilistic forecasting methods, such as expert systems or numerical models, can be evaluated against the standard set by simple persistence.},
	language = {EN},
	number = {1},
	urldate = {2022-07-05},
	journal = {Journal of Applied Meteorology and Climatology},
	author = {Germann, Urs and Zawadzki, Isztar},
	month = jan,
	year = {2004},
	note = {Publisher: American Meteorological Society
Section: Journal of Applied Meteorology and Climatology},
	pages = {74--89},
	file = {Full Text PDF:/home/harnist/Zotero/storage/44G9U7SW/Germann and Zawadzki - 2004 - Scale Dependence of the Predictability of Precipit.pdf:application/pdf;Snapshot:/home/harnist/Zotero/storage/Q2KSBZSL/1520-0450_2004_043_0074_sdotpo_2.0.co_2.html:text/html},
}

@article{bowler_steps_2006-1,
	title = {{STEPS}: {A} probabilistic precipitation forecasting scheme which merges an extrapolation nowcast with downscaled {NWP}},
	volume = {132},
	issn = {00359009, 1477870X},
	shorttitle = {{STEPS}},
	url = {http://doi.wiley.com/10.1256/qj.04.100},
	doi = {10.1256/qj.04.100},
	abstract = {An ensemble-based probabilistic precipitation forecasting scheme has been developed that blends an extrapolation nowcast with a downscaled NWP forecast, known as STEPS: Short-Term Ensemble Prediction System. The uncertainties in the motion and evolution of radar-inferred precipitation ﬁelds are quantiﬁed, and the uncertainty in the evolution of the precipitation pattern is shown to be the more important. The use of ensembles allows the scheme to be used for applications that require forecasts of the probability density function of areal and temporal averages of precipitation, such as ﬂuvial ﬂood forecasting—a capability that has not been provided by previous probabilistic precipitation nowcast schemes. The output from a NWP forecast model is downscaled so that the small scales not represented accurately by the model are injected into the forecast using stochastic noise. This allows the scheme to better represent the distribution of precipitation rate at spatial scales ﬁner than those adequately resolved by operational NWP. The performance of the scheme has been assessed over the month of March 2003. Performance evaluation statistics show that the scheme possesses predictive skill at lead times in excess of six hours.},
	language = {en},
	number = {620},
	urldate = {2022-07-05},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Bowler, Neill E. and Pierce, Clive E. and Seed, Alan W.},
	month = oct,
	year = {2006},
	pages = {2127--2155},
	file = {Bowler et al. - 2006 - STEPS A probabilistic precipitation forecasting s.pdf:/home/harnist/Zotero/storage/M7QS4569/Bowler et al. - 2006 - STEPS A probabilistic precipitation forecasting s.pdf:application/pdf},
}

@article{otsuka_precipitation_2016,
	title = {Precipitation {Nowcasting} with {Three}-{Dimensional} {Space} - {Time} {Extrapolation} of {Dense} and {Frequent} {Phased}-{Array} {Weather} {Radar} {Observations}},
	volume = {31},
	issn = {1520-0434, 0882-8156},
	url = {https://journals.ametsoc.org/view/journals/wefo/31/1/waf-d-15-0063_1.xml},
	doi = {10.1175/WAF-D-15-0063.1},
	abstract = {Abstract The phased-array weather radar (PAWR) is a new-generation weather radar that can make a 100-m-resolution three-dimensional (3D) volume scan every 30 s for 100 vertical levels, producing {\textasciitilde}100 times more data than the conventional parabolic-antenna radar with a volume scan typically made every 5 min for 15 scan levels. This study takes advantage of orders of magnitude more rapid and dense observations by PAWR and explores high-precision nowcasting of 3D evolution at 1-10-km scales up to several minutes, which are compared with conventional horizontal two-dimensional (2D) nowcasting typically at O(100) km scales up to 1-6 h. A new 3D precipitation extrapolation system was designed to enhance a conventional algorithm for dense and rapid PAWR volume scans. Experiments show that the 3D extrapolation successfully captured vertical motions of convective precipitation cores and outperformed 2D nowcasting with both simulated and real PAWR data.},
	language = {EN},
	number = {1},
	urldate = {2022-07-06},
	journal = {Weather and Forecasting},
	author = {Otsuka, Shigenori and Tuerhong, Gulanbaier and Kikuchi, Ryota and Kitano, Yoshikazu and Taniguchi, Yusuke and Ruiz, Juan Jose and Satoh, Shinsuke and Ushio, Tomoo and Miyoshi, Takemasa},
	month = feb,
	year = {2016},
	note = {Publisher: American Meteorological Society
Section: Weather and Forecasting},
	pages = {329--340},
	file = {Otsuka et al. - 2016 - Precipitation Nowcasting with Three-Dimensional Sp.pdf:/home/harnist/Zotero/storage/HRSUERDB/Otsuka et al. - 2016 - Precipitation Nowcasting with Three-Dimensional Sp.pdf:application/pdf;Snapshot:/home/harnist/Zotero/storage/UNG24SGS/waf-d-15-0063_1.html:text/html},
}

@article{voormansik_thunderstorm_2017,
	title = {Thunderstorm hail and lightning detection parameters based on dual-polarization {Doppler} weather radar data},
	volume = {24},
	issn = {1469-8080},
	url = {http://onlinelibrary.wiley.com/doi/abs/10.1002/met.1652},
	doi = {10.1002/met.1652},
	abstract = {Four years (2011–2014) of the summer period (May–September) dual-polarization Doppler C-band weather radar data for Sürgavere, Estonia, were examined to determine the best indicator for cloud-to-ground lightning activity. Furthermore, the legacy radar-derived hail indicator probability of hail and the storm maximum reflectivity were compared with the polarimetric hydrometeor classification algorithm (HCA) to establish a link between them and ensure data continuity. The study is based on convective storm cells identified from radar reflectivity data, using a 35 dBZ reflectivity threshold. Applying this threshold to the radar data resulted in 123 360 individual storm cells. It was found that 33.9\% of the identified cells produced lightning and 25.9\% hail. The number of individual storm cells on average is highest in the afternoon at 1600 local time and the mean storm cell area is largest in the evening at 2100 local time. Echo top 15 dBZ (ET15), ET20 and ET25 achieved the highest scores in terms of critical success index (0.39, 0.39 and 0.38 respectively), Heidke skill score (0.24, 0.26, 0.27) and equitable threat score (0.14, 0.15, 0.16). The graupel class of the dual-polarization radar hydrometeor classification showed a similar performance to the 35 dBZ echo top. It was also shown that the reflectivity value just below 50 dBZ indicates the best skill for detection of hail, if HCA hail detection is used as the ground truth. The probability of hail value that shows the best agreement with the HCA hail class is 0.2.},
	language = {en},
	number = {3},
	urldate = {2022-07-06},
	journal = {Meteorological Applications},
	author = {Voormansik, Tanel and Rossi, Pekka J. and Moisseev, Dmitri and Tanilsoo, Tarmo and Post, Piia},
	year = {2017},
	note = {\_eprint: https://rmets.onlinelibrary.wiley.com/doi/pdf/10.1002/met.1652},
	keywords = {automated detection, convective storm, hail, lightning, polarimetric weather radar},
	pages = {521--530},
	file = {Full Text PDF:/home/harnist/Zotero/storage/NCQ9MH84/Voormansik et al. - 2017 - Thunderstorm hail and lightning detection paramete.pdf:application/pdf},
}

@article{hogan_equitability_2010,
	title = {Equitability {Revisited}: {Why} the "{Equitable} {Threat} {Score}" {Is} {Not} {Equitable}},
	volume = {25},
	issn = {1520-0434, 0882-8156},
	shorttitle = {Equitability {Revisited}},
	url = {https://journals.ametsoc.org/view/journals/wefo/25/2/2009waf2222350_1.xml},
	doi = {10.1175/2009WAF2222350.1},
	abstract = {Abstract In the forecasting of binary events, verification measures that are “equitable” were defined by Gandin and Murphy to satisfy two requirements: 1) they award all random forecasting systems, including those that always issue the same forecast, the same expected score (typically zero), and 2) they are expressible as the linear weighted sum of the elements of the contingency table, where the weights are independent of the entries in the table, apart from the base rate. The authors demonstrate that the widely used “equitable threat score” (ETS), as well as numerous others, satisfies neither of these requirements and only satisfies the first requirement in the limit of an infinite sample size. Such measures are referred to as “asymptotically equitable.” In the case of ETS, the expected score of a random forecasting system is always positive and only falls below 0.01 when the number of samples is greater than around 30. Two other asymptotically equitable measures are the odds ratio skill score and the symmetric extreme dependency score, which are more strongly inequitable than ETS, particularly for rare events; for example, when the base rate is 2\% and the sample size is 1000, random but unbiased forecasting systems yield an expected score of around −0.5, reducing in magnitude to −0.01 or smaller only for sample sizes exceeding 25 000. This presents a problem since these nonlinear measures have other desirable properties, in particular being reliable indicators of skill for rare events (provided that the sample size is large enough). A potential way to reconcile these properties with equitability is to recognize that Gandin and Murphy’s two requirements are independent, and the second can be safely discarded without losing the key advantages of equitability that are embodied in the first. This enables inequitable and asymptotically equitable measures to be scaled to make them equitable, while retaining their nonlinearity and other properties such as being reliable indicators of skill for rare events. It also opens up the possibility of designing new equitable verification measures.},
	language = {EN},
	number = {2},
	urldate = {2022-07-06},
	journal = {Weather and Forecasting},
	author = {Hogan, Robin J. and Ferro, Christopher A. T. and Jolliffe, Ian T. and Stephenson, David B.},
	month = apr,
	year = {2010},
	note = {Publisher: American Meteorological Society
Section: Weather and Forecasting},
	pages = {710--726},
	file = {Full Text PDF:/home/harnist/Zotero/storage/SEZRJ7F2/Hogan et al. - 2010 - Equitability Revisited Why the “Equitable Threat .pdf:application/pdf;Snapshot:/home/harnist/Zotero/storage/89AHCUCK/2009waf2222350_1.html:text/html},
}

@article{schaefer_critical_1990,
	title = {The {Critical} {Success} {Index} as an {Indicator} of {Warning} {Skill}},
	volume = {5},
	issn = {1520-0434, 0882-8156},
	url = {https://journals.ametsoc.org/view/journals/wefo/5/4/1520-0434_1990_005_0570_tcsiaa_2_0_co_2.xml},
	doi = {10.1175/1520-0434(1990)005<0570:TCSIAA>2.0.CO;2},
	abstract = {Abstract A form of the critical success index (CSI) is used by the National Weather Service to indicate the value of warnings. This verification statistic assumes that the times when an event was neither expected nor observed are of no consequence. It can be shown that the CSI is not an unbiased indicator of forecast skill but is proportional to the frequency of the event being forecast. This innate bias is demonstrated theoretically and via example. An unbiased verification statistic appropriate for forecast of rare events is presented and applied to severe convective weather warnings. Comparisons of this score to the CSI show the extent of the penalty the CSI extracts from forecasters who work in areas that are not climatically prone to given events.},
	language = {EN},
	number = {4},
	urldate = {2022-07-06},
	journal = {Weather and Forecasting},
	author = {Schaefer, Joseph T.},
	month = dec,
	year = {1990},
	note = {Publisher: American Meteorological Society
Section: Weather and Forecasting},
	pages = {570--575},
	file = {Full Text PDF:/home/harnist/Zotero/storage/8XKRD2CH/Schaefer - 1990 - The Critical Success Index as an Indicator of Warn.pdf:application/pdf},
}
