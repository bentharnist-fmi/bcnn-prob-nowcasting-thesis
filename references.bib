
@article{shridhar_comprehensive_2019,
	title = {A {Comprehensive} guide to {Bayesian} {Convolutional} {Neural} {Network} with {Variational} {Inference}},
	url = {http://arxiv.org/abs/1901.02731},
	abstract = {Artificial Neural Networks are connectionist systems that perform a given task by learning on examples without having prior knowledge about the task. This is done by finding an optimal point estimate for the weights in every node. Generally, the network using point estimates as weights perform well with large datasets, but they fail to express uncertainty in regions with little or no data, leading to overconfident decisions. In this paper, Bayesian Convolutional Neural Network (BayesCNN) using Variational Inference is proposed, that introduces probability distribution over the weights. Furthermore, the proposed BayesCNN architecture is applied to tasks like Image Classification, Image Super-Resolution and Generative Adversarial Networks. The results are compared to point-estimates based architectures on MNIST, CIFAR-10 and CIFAR-100 datasets for Image CLassification task, on BSD300 dataset for Image Super Resolution task and on CIFAR10 dataset again for Generative Adversarial Network task. BayesCNN is based on Bayes by Backprop which derives a variational approximation to the true posterior. We, therefore, introduce the idea of applying two convolutional operations, one for the mean and one for the variance. Our proposed method not only achieves performances equivalent to frequentist inference in identical architectures but also incorporate a measurement for uncertainties and regularisation. It further eliminates the use of dropout in the model. Moreover, we predict how certain the model prediction is based on the epistemic and aleatoric uncertainties and empirically show how the uncertainty can decrease, allowing the decisions made by the network to become more deterministic as the training accuracy increases. Finally, we propose ways to prune the Bayesian architecture and to make it more computational and time effective.},
	urldate = {2022-03-18},
	journal = {arXiv:1901.02731 [cs, stat]},
	author = {Shridhar, Kumar and Laumann, Felix and Liwicki, Marcus},
	month = jan,
	year = {2019},
	note = {arXiv: 1901.02731},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:/home/harnist/Zotero/storage/LS296KMN/Shridhar et al. - 2019 - A Comprehensive guide to Bayesian Convolutional Ne.pdf:application/pdf;arXiv.org Snapshot:/home/harnist/Zotero/storage/XVEFISX3/1901.html:text/html},
}

@inproceedings{wang_multiscale_2003,
	address = {Pacific Grove, CA, USA},
	title = {Multiscale structural similarity for image quality assessment},
	isbn = {978-0-7803-8104-9},
	url = {http://ieeexplore.ieee.org/document/1292216/},
	doi = {10.1109/ACSSC.2003.1292216},
	language = {en},
	urldate = {2022-03-18},
	booktitle = {The {Thrity}-{Seventh} {Asilomar} {Conference} on {Signals}, {Systems} \& {Computers}, 2003},
	publisher = {IEEE},
	author = {Wang, Z. and Simoncelli, E.P. and Bovik, A.C.},
	year = {2003},
	pages = {1398--1402},
	file = {Wang et al. - 2003 - Multiscale structural similarity for image quality.pdf:/home/harnist/Zotero/storage/DWTIUX7H/Wang et al. - 2003 - Multiscale structural similarity for image quality.pdf:application/pdf},
}

@article{blundell_weight_2015,
	title = {Weight {Uncertainty} in {Neural} {Networks}},
	url = {http://arxiv.org/abs/1505.05424},
	abstract = {We introduce a new, efﬁcient, principled and backpropagation-compatible algorithm for learning a probability distribution on the weights of a neural network, called Bayes by Backprop. It regularises the weights by minimising a compression cost, known as the variational free energy or the expected lower bound on the marginal likelihood. We show that this principled kind of regularisation yields comparable performance to dropout on MNIST classiﬁcation. We then demonstrate how the learnt uncertainty in the weights can be used to improve generalisation in non-linear regression problems, and how this weight uncertainty can be used to drive the exploration-exploitation trade-off in reinforcement learning.},
	language = {en},
	urldate = {2022-03-21},
	journal = {arXiv:1505.05424 [cs, stat]},
	author = {Blundell, Charles and Cornebise, Julien and Kavukcuoglu, Koray and Wierstra, Daan},
	month = may,
	year = {2015},
	note = {arXiv: 1505.05424},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {Blundell et al. - 2015 - Weight Uncertainty in Neural Networks.pdf:/home/harnist/Zotero/storage/3UGR5FY5/Blundell et al. - 2015 - Weight Uncertainty in Neural Networks.pdf:application/pdf},
}

@article{ayzel_rainnet_nodate,
	title = {{RainNet} v1.0: a convolutional neural network for radar-based precipitation nowcasting},
	abstract = {In this study, we present RainNet, a deep convolutional neural network for radar-based precipitation nowcasting. Its design was inspired by the U-Net and SegNet families of deep learning models which were originally designed for binary segmentation tasks. RainNet was trained to predict continuous precipitation intensities at a lead time of ﬁve minutes, using several years of quality-controlled weather radar composites provided by the German Weather Service (DWD). That data 5 set covers Germany with a spatial domain of 900×900 km, and has a resolution of 1 km in space and 5 minutes in time. Independent veriﬁcation experiments were carried out on eleven summer precipitation events from 2016 to 2017. In order to achieve a lead time of one hour, a recursive approach was implemented by using RainNet predictions at ﬁve minutes lead time as model input for longer lead times. In the veriﬁcation experiments, trivial Eulerian persistence and a conventional model based on optical ﬂow served as benchmarks. The latter is available in the rainymotion library, and had previously been shown 10 to outperform DWD’s operational nowcasting model for the same set of veriﬁcation events.},
	language = {en},
	author = {Ayzel, Georgy and Scheffer, Tobias and Heistermann, Maik},
	pages = {21},
	file = {Ayzel et al. - RainNet v1.0 a convolutional neural network for r.pdf:/home/harnist/Zotero/storage/CT2QNK7A/Ayzel et al. - RainNet v1.0 a convolutional neural network for r.pdf:application/pdf},
}

@article{zhao_loss_2017,
	title = {Loss {Functions} for {Image} {Restoration} {With} {Neural} {Networks}},
	volume = {3},
	issn = {2333-9403},
	doi = {10.1109/TCI.2016.2644865},
	abstract = {Neural networks are becoming central in several areas of computer vision and image processing and different architectures have been proposed to solve specific problems. The impact of the loss layer of neural networks, however, has not received much attention in the context of image processing: the default and virtually only choice is ℓ2. In this paper, we bring attention to alternative choices for image restoration. In particular, we show the importance of perceptually-motivated losses when the resulting image is to be evaluated by a human observer. We compare the performance of several losses, and propose a novel, differentiable error function. We show that the quality of the results improves significantly with better loss functions, even when the network architecture is left unchanged.},
	number = {1},
	journal = {IEEE Transactions on Computational Imaging},
	author = {Zhao, Hang and Gallo, Orazio and Frosio, Iuri and Kautz, Jan},
	month = mar,
	year = {2017},
	note = {Conference Name: IEEE Transactions on Computational Imaging},
	keywords = {Neural networks, Measurement, neural networks, Image processing, Image quality, image restoration, Image restoration, loss functions},
	pages = {47--57},
	file = {IEEE Xplore Abstract Record:/home/harnist/Zotero/storage/69499HEH/7797130.html:text/html;IEEE Xplore Full Text PDF:/home/harnist/Zotero/storage/5DIXBZ39/Zhao et al. - 2017 - Loss Functions for Image Restoration With Neural N.pdf:application/pdf},
}

@article{prudden_review_2020,
	title = {A review of radar-based nowcasting of precipitation and applicable machine learning techniques},
	url = {http://arxiv.org/abs/2005.04988},
	abstract = {A ‘nowcast’ is a type of weather forecast which makes predictions in the very short term, typically less than two hours - a period in which traditional numerical weather prediction can be limited. This type of weather prediction has important applications for commercial aviation; public and outdoor events; and the construction industry, power utilities, and ground transportation services that conduct much of their work outdoors. Importantly, one of the key needs for nowcasting systems is in the provision of accurate warnings of adverse weather events, such as heavy rain and ﬂooding, for the protection of life and property in such situations. Typical nowcasting approaches are based on simple extrapolation models applied to observations, primarily rainfall radar. In this paper we review existing techniques to radar-based nowcasting from environmental sciences, as well as the statistical approaches that are applicable from the ﬁeld of machine learning. Nowcasting continues to be an important component of operational systems and we believe new advances are possible with new partnerships between the environmental science and machine learning communities.},
	language = {en},
	urldate = {2022-03-30},
	journal = {arXiv:2005.04988 [physics, stat]},
	author = {Prudden, Rachel and Adams, Samantha and Kangin, Dmitry and Robinson, Niall and Ravuri, Suman and Mohamed, Shakir and Arribas, Alberto},
	month = may,
	year = {2020},
	note = {arXiv: 2005.04988},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Physics - Atmospheric and Oceanic Physics},
	file = {Prudden et al. - 2020 - A review of radar-based nowcasting of precipitatio.pdf:/home/harnist/Zotero/storage/IHWXM9WN/Prudden et al. - 2020 - A review of radar-based nowcasting of precipitatio.pdf:application/pdf},
}

@article{schultz_can_2021,
	title = {Can deep learning beat numerical weather prediction?},
	volume = {379},
	url = {https://royalsocietypublishing.org/doi/10.1098/rsta.2020.0097},
	doi = {10.1098/rsta.2020.0097},
	abstract = {The recent hype about artificial intelligence has sparked renewed interest in applying the successful deep learning (DL) methods for image recognition, speech recognition, robotics, strategic games and other application areas to the field of meteorology. There is some evidence that better weather forecasts can be produced by introducing big data mining and neural networks into the weather prediction workflow. Here, we discuss the question of whether it is possible to completely replace the current numerical weather models and data assimilation systems with DL approaches. This discussion entails a review of state-of-the-art machine learning concepts and their applicability to weather data with its pertinent statistical properties. We think that it is not inconceivable that numerical weather models may one day become obsolete, but a number of fundamental breakthroughs are needed before this goal comes into reach.

This article is part of the theme issue ‘Machine learning for weather and climate modelling’.},
	number = {2194},
	urldate = {2022-04-14},
	journal = {Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
	author = {Schultz, M. G. and Betancourt, C. and Gong, B. and Kleinert, F. and Langguth, M. and Leufen, L. H. and Mozaffari, A. and Stadtler, S.},
	month = apr,
	year = {2021},
	note = {Publisher: Royal Society},
	keywords = {deep learning, machine learning, numerical weather prediction, spatiotemporal pattern recognition, weather AI},
	pages = {20200097},
	file = {Full Text PDF:/home/harnist/Zotero/storage/WRWXYS7G/Schultz et al. - 2021 - Can deep learning beat numerical weather predictio.pdf:application/pdf},
}

@article{kingma_variational_2015,
	title = {Variational {Dropout} and the {Local} {Reparameterization} {Trick}},
	url = {http://arxiv.org/abs/1506.02557},
	abstract = {We investigate a local reparameterizaton technique for greatly reducing the variance of stochastic gradients for variational Bayesian inference (SGVB) of a posterior over model parameters, while retaining parallelizability. This local reparameterization translates uncertainty about global parameters into local noise that is independent across datapoints in the minibatch. Such parameterizations can be trivially parallelized and have variance that is inversely proportional to the minibatch size, generally leading to much faster convergence. Additionally, we explore a connection with dropout: Gaussian dropout objectives correspond to SGVB with local reparameterization, a scale-invariant prior and proportionally ﬁxed posterior variance. Our method allows inference of more ﬂexibly parameterized posteriors; speciﬁcally, we propose variational dropout, a generalization of Gaussian dropout where the dropout rates are learned, often leading to better models. The method is demonstrated through several experiments.},
	language = {en},
	urldate = {2022-04-23},
	journal = {arXiv:1506.02557 [cs, stat]},
	author = {Kingma, Diederik P. and Salimans, Tim and Welling, Max},
	month = dec,
	year = {2015},
	note = {arXiv: 1506.02557},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Statistics - Computation},
	file = {Kingma et al. - 2015 - Variational Dropout and the Local Reparameterizati.pdf:/home/harnist/Zotero/storage/3WLN42UA/Kingma et al. - 2015 - Variational Dropout and the Local Reparameterizati.pdf:application/pdf},
}

@article{kendall_what_2017,
	title = {What {Uncertainties} {Do} {We} {Need} in {Bayesian} {Deep} {Learning} for {Computer} {Vision}?},
	url = {http://arxiv.org/abs/1703.04977},
	abstract = {There are two major types of uncertainty one can model. Aleatoric uncertainty captures noise inherent in the observations. On the other hand, epistemic uncertainty accounts for uncertainty in the model -- uncertainty which can be explained away given enough data. Traditionally it has been difficult to model epistemic uncertainty in computer vision, but with new Bayesian deep learning tools this is now possible. We study the benefits of modeling epistemic vs. aleatoric uncertainty in Bayesian deep learning models for vision tasks. For this we present a Bayesian deep learning framework combining input-dependent aleatoric uncertainty together with epistemic uncertainty. We study models under the framework with per-pixel semantic segmentation and depth regression tasks. Further, our explicit uncertainty formulation leads to new loss functions for these tasks, which can be interpreted as learned attenuation. This makes the loss more robust to noisy data, also giving new state-of-the-art results on segmentation and depth regression benchmarks.},
	urldate = {2022-05-02},
	journal = {arXiv:1703.04977 [cs]},
	author = {Kendall, Alex and Gal, Yarin},
	month = oct,
	year = {2017},
	note = {arXiv: 1703.04977},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:/home/harnist/Zotero/storage/5IPAGIW7/Kendall and Gal - 2017 - What Uncertainties Do We Need in Bayesian Deep Lea.pdf:application/pdf;arXiv.org Snapshot:/home/harnist/Zotero/storage/UWYCDGER/1703.html:text/html},
}

@article{bowler_steps_2006,
	title = {{STEPS}: {A} probabilistic precipitation forecasting scheme which merges an extrapolation nowcast with downscaled {NWP}},
	volume = {132},
	issn = {1477-870X},
	shorttitle = {{STEPS}},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1256/qj.04.100},
	doi = {10.1256/qj.04.100},
	abstract = {An ensemble-based probabilistic precipitation forecasting scheme has been developed that blends an extrapolation nowcast with a downscaled NWP forecast, known as STEPS: Short-Term Ensemble Prediction System. The uncertainties in the motion and evolution of radar-inferred precipitation fields are quantified, and the uncertainty in the evolution of the precipitation pattern is shown to be the more important. The use of ensembles allows the scheme to be used for applications that require forecasts of the probability density function of areal and temporal averages of precipitation, such as fluvial flood forecasting—a capability that has not been provided by previous probabilistic precipitation nowcast schemes. The output from a NWP forecast model is downscaled so that the small scales not represented accurately by the model are injected into the forecast using stochastic noise. This allows the scheme to better represent the distribution of precipitation rate at spatial scales finer than those adequately resolved by operational NWP. The performance of the scheme has been assessed over the month of March 2003. Performance evaluation statistics show that the scheme possesses predictive skill at lead times in excess of six hours. © Crown copyright, 2006.},
	language = {en},
	number = {620},
	urldate = {2022-06-05},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Bowler, Neill E. and Pierce, Clive E. and Seed, Alan W.},
	year = {2006},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1256/qj.04.100},
	keywords = {Ensemble, Noise cascade, S-PROG},
	pages = {2127--2155},
	file = {Snapshot:/home/harnist/Zotero/storage/BM59WJDX/qj.04.html:text/html},
}

@article{pulkkinen_lagrangian_2021,
	title = {Lagrangian {Integro}-{Difference} {Equation} {Model} for {Precipitation} {Nowcasting}},
	volume = {38},
	issn = {0739-0572, 1520-0426},
	url = {https://journals.ametsoc.org/view/journals/atot/38/12/JTECH-D-21-0013.1.xml},
	doi = {10.1175/JTECH-D-21-0013.1},
	abstract = {Abstract Delivering reliable nowcasts (short-range forecasts) of severe rainfall and the resulting flash floods is important in densely populated urban areas. The conventional method is advection-based extrapolation of radar echoes. However, during rapidly evolving convective rainfall this so-called Lagrangian persistence (LP) approach is limited to deterministic and very short-range nowcasts. To address these limitations in the 1-h time range, a novel extension of LP, called Lagrangian Integro-Difference equation model with Autoregression (LINDA), is proposed. The model consists of five components: 1) identification of rain cells, 2) advection, 3) autoregressive process describing growth and decay of the cells, 4) convolution describing loss of predictability at small scales, and 5) stochastic perturbations to simulate forecast uncertainty. Advection is separated from the other components that are applied in the Lagrangian coordinates. The reliability of LINDA is evaluated using the NEXRAD WSR-88D radar that covers the Dallas–Fort Worth metropolitan area, as well as the NEXRAD mosaic covering the continental United States. This is done with two different configurations: LINDA-D for deterministic and LINDA-P for probabilistic nowcasts. The validation dataset consists of 11 rainfall events during 2018–20. For predicting moderate to heavy rainfall (5–20 mm h−1), LINDA outperforms the previously proposed LP-based approaches. The most significant improvement is seen for the ETS and POD statistics with the 5 mm h−1 threshold. For 30-min nowcasts, they show 15\% and 16\% increases, respectively, to the second-best method and 48\% and 34\% increases compared to LP. For the 5 mm h−1 threshold, the increase in the relative operating characteristic (ROC) skill score of 30-min nowcasts from the second-best method is 10\%. Significance Statement Delivering reliable forecasts of severe rainfall for the next few hours has a major societal importance. This is particularly true for densely populated urban areas, where flash floods can cause property damage and loss of lives. Such forecasts are conventionally produced by direct extrapolation of weather radar measurements. However, for intense localized rainfall this approach has low prediction ability beyond 30 min. To extend this limit, we propose a novel method that combines machine vision with a statistical model for growth and decay of rainfall. The method is designed for predicting highly localized rain cells and bands. In addition, a stochastic extension for producing probabilistic forecasts is developed. Using several verification metrics, we demonstrate that for predicting moderate to heavy rainfall (5–20 mm h−1), the proposed method has significantly improved forecast skill compared to the reference methods. The evaluation is done by using the NEXRAD WSR-88D that covers the Dallas–Fort Worth urban metroplex with a population of over 7 million. Demonstration of the applicability of LINDA in a larger domain is done by using the NEXRAD radar network that covers the continental United States.},
	language = {EN},
	number = {12},
	urldate = {2022-06-05},
	journal = {Journal of Atmospheric and Oceanic Technology},
	author = {Pulkkinen, Seppo and Chandrasekar, V. and Niemi, Tero},
	month = dec,
	year = {2021},
	note = {Publisher: American Meteorological Society
Section: Journal of Atmospheric and Oceanic Technology},
	pages = {2125--2145},
	file = {Snapshot:/home/harnist/Zotero/storage/XALGXCJ2/JTECH-D-21-0013.1.html:text/html},
}

@article{ravuri_skilful_2021,
	title = {Skilful precipitation nowcasting using deep generative models of radar},
	volume = {597},
	copyright = {2021 The Author(s)},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/s41586-021-03854-z},
	doi = {10.1038/s41586-021-03854-z},
	abstract = {Precipitation nowcasting, the high-resolution forecasting of precipitation up to two hours ahead, supports the real-world socioeconomic needs of many sectors reliant on weather-dependent decision-making1,2. State-of-the-art operational nowcasting methods typically advect precipitation fields with radar-based wind estimates, and struggle to capture important non-linear events such as convective initiations3,4. Recently introduced deep learning methods use radar to directly predict future rain rates, free of physical constraints5,6. While they accurately predict low-intensity rainfall, their operational utility is limited because their lack of constraints produces blurry nowcasts at longer lead times, yielding poor performance on rarer medium-to-heavy rain events. Here we present a deep generative model for the probabilistic nowcasting of precipitation from radar that addresses these challenges. Using statistical, economic and cognitive measures, we show that our method provides improved forecast quality, forecast consistency and forecast value. Our model produces realistic and spatiotemporally consistent predictions over regions up to 1,536 km × 1,280 km and with lead times from 5–90 min ahead. Using a systematic evaluation by more than 50 expert meteorologists, we show that our generative model ranked first for its accuracy and usefulness in 89\% of cases against two competitive methods. When verified quantitatively, these nowcasts are skillful without resorting to blurring. We show that generative nowcasting can provide probabilistic predictions that improve forecast value and support operational utility, and at resolutions and lead times where alternative methods struggle.},
	language = {en},
	number = {7878},
	urldate = {2022-06-05},
	journal = {Nature},
	author = {Ravuri, Suman and Lenc, Karel and Willson, Matthew and Kangin, Dmitry and Lam, Remi and Mirowski, Piotr and Fitzsimons, Megan and Athanassiadou, Maria and Kashem, Sheleem and Madge, Sam and Prudden, Rachel and Mandhane, Amol and Clark, Aidan and Brock, Andrew and Simonyan, Karen and Hadsell, Raia and Robinson, Niall and Clancy, Ellen and Arribas, Alberto and Mohamed, Shakir},
	month = sep,
	year = {2021},
	note = {Number: 7878
Publisher: Nature Publishing Group},
	keywords = {Computer science, Environmental sciences},
	pages = {672--677},
	file = {Full Text PDF:/home/harnist/Zotero/storage/HQ5EZ7YS/Ravuri et al. - 2021 - Skilful precipitation nowcasting using deep genera.pdf:application/pdf;Snapshot:/home/harnist/Zotero/storage/LKG6QAWB/s41586-021-03854-z.html:text/html},
}

@article{mcallister_concrete_2017,
	title = {Concrete {Problems} for {Autonomous} {Vehicle} {Safety}: {Advantages} of {Bayesian} {Deep} {Learning}},
	shorttitle = {Concrete {Problems} for {Autonomous} {Vehicle} {Safety}},
	url = {https://www.ijcai.org/proceedings/2017/661},
	abstract = {Electronic proceedings of IJCAI 2017},
	urldate = {2022-06-05},
	author = {McAllister, Rowan and Gal, Yarin and Kendall, Alex and Wilk, Mark van der and Shah, Amar and Cipolla, Roberto and Weller, Adrian},
	year = {2017},
	pages = {4745--4753},
	file = {Snapshot:/home/harnist/Zotero/storage/V3XWLAH6/661.html:text/html},
}

@article{kwon_uncertainty_2020,
	title = {Uncertainty quantification using {Bayesian} neural networks in classification: {Application} to biomedical image segmentation},
	volume = {142},
	issn = {0167-9473},
	shorttitle = {Uncertainty quantification using {Bayesian} neural networks in classification},
	url = {https://www.sciencedirect.com/science/article/pii/S016794731930163X},
	doi = {10.1016/j.csda.2019.106816},
	abstract = {Most recent research of deep neural networks in the field of computer vision has focused on improving performances of point predictions by developing network architectures or learning algorithms. Reliable uncertainty quantification accompanied by point estimation can lead to a more informed decision, and the quality of prediction can be improved. In this paper, we invoke a Bayesian neural network and propose a natural way of quantifying uncertainties in classification problems by decomposing the moment-based predictive uncertainty into two parts: aleatoric and epistemic uncertainty. The proposed method takes into account the discrete nature of the outcome, yielding the correct interpretation of each uncertainty. We demonstrate that the proposed uncertainty quantification method provides additional insights into the point prediction using two Ischemic Stroke Lesion Segmentation Challenge datasets and the Digital Retinal Images for Vessel Extraction dataset.},
	language = {en},
	urldate = {2022-06-05},
	journal = {Computational Statistics \& Data Analysis},
	author = {Kwon, Yongchan and Won, Joong-Ho and Kim, Beom Joon and Paik, Myunghee Cho},
	month = feb,
	year = {2020},
	keywords = {Aleatoric and epistemic uncertainty, Bayesian neural network, Ischemic stroke lesion segmentation, Retinal blood vessel segmentation, Uncertainty quantification},
	pages = {106816},
	file = {ScienceDirect Snapshot:/home/harnist/Zotero/storage/ULPTAHPZ/S016794731930163X.html:text/html},
}

@misc{ziyin_neural_2020,
	title = {Neural {Networks} {Fail} to {Learn} {Periodic} {Functions} and {How} to {Fix} {It}},
	url = {http://arxiv.org/abs/2006.08195},
	abstract = {Previous literature offers limited clues on how to learn a periodic function using modern neural networks. We start with a study of the extrapolation properties of neural networks; we prove and demonstrate experimentally that the standard activations functions, such as ReLU, tanh, sigmoid, along with their variants, all fail to learn to extrapolate simple periodic functions. We hypothesize that this is due to their lack of a “periodic” inductive bias. As a ﬁx of this problem, we propose a new activation, namely, x + sin2(x), which achieves the desired periodic inductive bias to learn a periodic function while maintaining a favorable optimization property of the ReLU-based activations. Experimentally, we apply the proposed method to temperature and ﬁnancial data prediction.},
	language = {en},
	urldate = {2022-06-06},
	publisher = {arXiv},
	author = {Ziyin, Liu and Hartwig, Tilman and Ueda, Masahito},
	month = oct,
	year = {2020},
	note = {Number: arXiv:2006.08195
arXiv:2006.08195 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {Ziyin et al. - 2020 - Neural Networks Fail to Learn Periodic Functions a.pdf:/home/harnist/Zotero/storage/IMPNBHCX/Ziyin et al. - 2020 - Neural Networks Fail to Learn Periodic Functions a.pdf:application/pdf},
}

@misc{ziyin_neural_2020-1,
	title = {Neural {Networks} {Fail} to {Learn} {Periodic} {Functions} and {How} to {Fix} {It}},
	url = {http://arxiv.org/abs/2006.08195},
	abstract = {Previous literature offers limited clues on how to learn a periodic function using modern neural networks. We start with a study of the extrapolation properties of neural networks; we prove and demonstrate experimentally that the standard activations functions, such as ReLU, tanh, sigmoid, along with their variants, all fail to learn to extrapolate simple periodic functions. We hypothesize that this is due to their lack of a “periodic” inductive bias. As a ﬁx of this problem, we propose a new activation, namely, x + sin2(x), which achieves the desired periodic inductive bias to learn a periodic function while maintaining a favorable optimization property of the ReLU-based activations. Experimentally, we apply the proposed method to temperature and ﬁnancial data prediction.},
	language = {en},
	urldate = {2022-06-06},
	publisher = {arXiv},
	author = {Ziyin, Liu and Hartwig, Tilman and Ueda, Masahito},
	month = oct,
	year = {2020},
	note = {Number: arXiv:2006.08195
arXiv:2006.08195 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {Ziyin et al. - 2020 - Neural Networks Fail to Learn Periodic Functions a.pdf:/home/harnist/Zotero/storage/6PYDCR6B/Ziyin et al. - 2020 - Neural Networks Fail to Learn Periodic Functions a.pdf:application/pdf},
}

@article{pulkkinen_pysteps_2019,
	title = {Pysteps: an open-source {Python} library for probabilistic precipitation nowcasting (v1.0)},
	volume = {12},
	issn = {1991-959X},
	shorttitle = {Pysteps},
	url = {https://gmd.copernicus.org/articles/12/4185/2019/},
	doi = {10.5194/gmd-12-4185-2019},
	abstract = {{\textless}p{\textgreater}{\textless}strong class="journal-contentHeaderColor"{\textgreater}Abstract.{\textless}/strong{\textgreater} Pysteps is an open-source and community-driven Python library for probabilistic precipitation nowcasting, that is, very-short-range forecasting (0–6\&thinsp;h). The aim of pysteps is to serve two different needs. The first is to provide a modular and well-documented framework for researchers interested in developing new methods for nowcasting and stochastic space–time simulation of precipitation. The second aim is to offer a highly configurable and easily accessible platform for practitioners ranging from weather forecasters to hydrologists. In this sense, pysteps has the potential to become an important component for integrated early warning systems for severe weather.{\textless}/p{\textgreater} {\textless}p{\textgreater}The pysteps library supports various input/output file formats and implements several optical flow methods as well as advanced stochastic generators to produce ensemble nowcasts. In addition, it includes tools for visualizing and post-processing the nowcasts and methods for deterministic, probabilistic and neighborhood forecast verification. The pysteps library is described and its potential is demonstrated using radar composite images from Finland, Switzerland, the United States and Australia. Finally, scientific experiments are carried out to help the reader to understand the pysteps framework and sensitivity to model parameters.{\textless}/p{\textgreater}},
	language = {English},
	number = {10},
	urldate = {2022-06-13},
	journal = {Geoscientific Model Development},
	author = {Pulkkinen, Seppo and Nerini, Daniele and Pérez Hortal, Andrés A. and Velasco-Forero, Carlos and Seed, Alan and Germann, Urs and Foresti, Loris},
	month = oct,
	year = {2019},
	note = {Publisher: Copernicus GmbH},
	pages = {4185--4219},
	file = {Full Text PDF:/home/harnist/Zotero/storage/5KRQPZJG/Pulkkinen et al. - 2019 - Pysteps an open-source Python library for probabi.pdf:application/pdf;Snapshot:/home/harnist/Zotero/storage/HHJ5MKIS/2019.html:text/html},
}

@article{roberts_scale-selective_2008,
	title = {Scale-{Selective} {Verification} of {Rainfall} {Accumulations} from {High}-{Resolution} {Forecasts} of {Convective} {Events}},
	volume = {136},
	issn = {1520-0493, 0027-0644},
	url = {https://journals.ametsoc.org/view/journals/mwre/136/1/2007mwr2123.1.xml},
	doi = {10.1175/2007MWR2123.1},
	abstract = {Abstract The development of NWP models with grid spacing down to ∼1 km should produce more realistic forecasts of convective storms. However, greater realism does not necessarily mean more accurate precipitation forecasts. The rapid growth of errors on small scales in conjunction with preexisting errors on larger scales may limit the usefulness of such models. The purpose of this paper is to examine whether improved model resolution alone is able to produce more skillful precipitation forecasts on useful scales, and how the skill varies with spatial scale. A verification method will be described in which skill is determined from a comparison of rainfall forecasts with radar using fractional coverage over different sized areas. The Met Office Unified Model was run with grid spacings of 12, 4, and 1 km for 10 days in which convection occurred during the summers of 2003 and 2004. All forecasts were run from 12-km initial states for a clean comparison. The results show that the 1-km model was the most skillful over all but the smallest scales (approximately {\textless}10–15 km). A measure of acceptable skill was defined; this was attained by the 1-km model at scales around 40–70 km, some 10–20 km less than that of the 12-km model. The biggest improvement occurred for heavier, more localized rain, despite it being more difficult to predict. The 4-km model did not improve much on the 12-km model because of the difficulties of representing convection at that resolution, which was accentuated by the spinup from 12-km fields.},
	language = {EN},
	number = {1},
	urldate = {2022-06-20},
	journal = {Monthly Weather Review},
	author = {Roberts, Nigel M. and Lean, Humphrey W.},
	month = jan,
	year = {2008},
	note = {Publisher: American Meteorological Society
Section: Monthly Weather Review},
	pages = {78--97},
	file = {Full Text PDF:/home/harnist/Zotero/storage/TFMNVQIN/Roberts and Lean - 2008 - Scale-Selective Verification of Rainfall Accumulat.pdf:application/pdf;Snapshot:/home/harnist/Zotero/storage/ASGW6IZM/2007mwr2123.1.html:text/html},
}

@article{minka_family_nodate,
	title = {A family of algorithms for approximate {Bayesian} inference},
	abstract = {One of the major obstacles to using Bayesian methods for pattern recognition has been its computational expense. This thesis presents an approximation technique that can perform Bayesian inference faster and more accurately than previously possible. This method, "Expectation Propagation," unifies and generalizes two previous techniques: assumeddensity filtering, an extension of the Kalman filter, and loopy belief propagation, an extension of belief propagation in Bayesian networks. The unification shows how both of these algorithms can be viewed as approximating the true posterior distribution with a simpler distribution, which is close in the sense of KL-divergence. Expectation Propagation exploits the best of both algorithms: the generality of assumed-density filtering and the accuracy of loopy belief propagation. Loopy belief propagation, because it propagates exact belief states, is useful for limited types of belief networks, such as purely discrete networks. Expectation Propagation approximates the belief states with expectations, such as means and variances, giving it much wider scope. Expectation Propagation also extends belief propagation in the opposite direction-propagating richer belief states which incorporate correlations between variables. This framework is demonstrated in a variety of statistical models using synthetic and real-world data. On Gaussian mixture problems, Expectation Propagation is found, for the same amount of computation, to be convincingly better than rival approximation techniques: Monte Carlo, Laplace's method, and variational Bayes. For pattern recognition, Expectation Propagation provides an algorithm for training Bayes Point Machine classifiers that is faster and more accurate than any previously known. The resulting classifiers outperform Support Vector Machines on several standard datasets, in addition to having a comparable training time. Expectation Propagation can also be used to choose an appropriate feature set for classification, via Bayesian model selection.},
	language = {en},
	author = {Minka, Thomas P},
	pages = {75},
	file = {Minka - A family of algorithms for approximate Bayesian in.pdf:/home/harnist/Zotero/storage/7ZMD7R6V/Minka - A family of algorithms for approximate Bayesian in.pdf:application/pdf},
}

@article{minka_family_nodate-1,
	title = {A family of algorithms for approximate {Bayesian} inference},
	abstract = {One of the major obstacles to using Bayesian methods for pattern recognition has been its computational expense. This thesis presents an approximation technique that can perform Bayesian inference faster and more accurately than previously possible. This method, "Expectation Propagation," unifies and generalizes two previous techniques: assumeddensity filtering, an extension of the Kalman filter, and loopy belief propagation, an extension of belief propagation in Bayesian networks. The unification shows how both of these algorithms can be viewed as approximating the true posterior distribution with a simpler distribution, which is close in the sense of KL-divergence. Expectation Propagation exploits the best of both algorithms: the generality of assumed-density filtering and the accuracy of loopy belief propagation. Loopy belief propagation, because it propagates exact belief states, is useful for limited types of belief networks, such as purely discrete networks. Expectation Propagation approximates the belief states with expectations, such as means and variances, giving it much wider scope. Expectation Propagation also extends belief propagation in the opposite direction-propagating richer belief states which incorporate correlations between variables. This framework is demonstrated in a variety of statistical models using synthetic and real-world data. On Gaussian mixture problems, Expectation Propagation is found, for the same amount of computation, to be convincingly better than rival approximation techniques: Monte Carlo, Laplace's method, and variational Bayes. For pattern recognition, Expectation Propagation provides an algorithm for training Bayes Point Machine classifiers that is faster and more accurate than any previously known. The resulting classifiers outperform Support Vector Machines on several standard datasets, in addition to having a comparable training time. Expectation Propagation can also be used to choose an appropriate feature set for classification, via Bayesian model selection.},
	language = {en},
	author = {Minka, Thomas P},
	pages = {75},
	file = {Minka - A family of algorithms for approximate Bayesian in.pdf:/home/harnist/Zotero/storage/CF5FF3JY/Minka - A family of algorithms for approximate Bayesian in.pdf:application/pdf},
}

@article{graves_practical_2011,
	title = {Practical {Variational} {Inference} for {Neural} {Networks}},
	abstract = {Variational methods have been previously explored as a tractable approximation to Bayesian inference for neural networks. However the approaches proposed so far have only been applicable to a few simple network architectures. This paper introduces an easy-to-implement stochastic variational method (or equivalently, minimum description length loss function) that can be applied to most neural networks. Along the way it revisits several common regularisers from a variational perspective. It also provides a simple pruning heuristic that can both drastically reduce the number of network weights and lead to improved generalisation. Experimental results are provided for a hierarchical multidimensional recurrent neural network applied to the TIMIT speech corpus.},
	language = {en},
	author = {Graves, Alex},
	year = {2011},
	pages = {9},
	file = {Graves - Practical Variational Inference for Neural Network.pdf:/home/harnist/Zotero/storage/RZVB4ZH8/Graves - Practical Variational Inference for Neural Network.pdf:application/pdf},
}

@article{hinton_keeping_1993,
	title = {Keeping {Neural} {Networks} {Simple} by {Minimizing} the {Description} {Length} of the {Weights}},
	abstract = {Supervised neural networks generalize well if there is much less information in the weights than there is in the output vectors of the training cases. So during learning, it is important to keep the weights simple by penalizing the amount of information they contain. The amount of information in a weight can be controlled by adding Gaussian noise and the noise level can be adapted during learning to optimize the trade-off between the expected squared error of the network and the amount of information in the weights. We describe a method of computing the derivatives of the expected squared error and of the amount of information in the noisy weights in a network that contains a layer of non-linear hidden units. Provided the output units are linear, the exact derivatives can be computed efficiently without time-consuming Monte Carlo simulations. The idea of minimizing the amount of information that is required to communicate the weights of a neural network leads to a number of intereating schemes for encoding the weights.},
	language = {en},
	author = {Hinton, E},
	year = {1993},
	pages = {9},
	file = {Hinton - Keeping Neural Networks Simple by Minimizing the D.pdf:/home/harnist/Zotero/storage/J8JL6VNU/Hinton - Keeping Neural Networks Simple by Minimizing the D.pdf:application/pdf},
}

@misc{wen_flipout_2018,
	title = {Flipout: {Efficient} {Pseudo}-{Independent} {Weight} {Perturbations} on {Mini}-{Batches}},
	shorttitle = {Flipout},
	url = {http://arxiv.org/abs/1803.04386},
	doi = {10.48550/arXiv.1803.04386},
	abstract = {Stochastic neural net weights are used in a variety of contexts, including regularization, Bayesian neural nets, exploration in reinforcement learning, and evolution strategies. Unfortunately, due to the large number of weights, all the examples in a mini-batch typically share the same weight perturbation, thereby limiting the variance reduction effect of large mini-batches. We introduce flipout, an efficient method for decorrelating the gradients within a mini-batch by implicitly sampling pseudo-independent weight perturbations for each example. Empirically, flipout achieves the ideal linear variance reduction for fully connected networks, convolutional networks, and RNNs. We find significant speedups in training neural networks with multiplicative Gaussian perturbations. We show that flipout is effective at regularizing LSTMs, and outperforms previous methods. Flipout also enables us to vectorize evolution strategies: in our experiments, a single GPU with flipout can handle the same throughput as at least 40 CPU cores using existing methods, equivalent to a factor-of-4 cost reduction on Amazon Web Services.},
	urldate = {2022-06-23},
	publisher = {arXiv},
	author = {Wen, Yeming and Vicol, Paul and Ba, Jimmy and Tran, Dustin and Grosse, Roger},
	month = apr,
	year = {2018},
	note = {Number: arXiv:1803.04386
arXiv:1803.04386 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:/home/harnist/Zotero/storage/DF573ZIF/Wen et al. - 2018 - Flipout Efficient Pseudo-Independent Weight Pertu.pdf:application/pdf;arXiv.org Snapshot:/home/harnist/Zotero/storage/NYV22LMI/1803.html:text/html},
}

@misc{noauthor_svi_nodate,
	title = {{SVI} {Part} {IV}: {Tips} and {Tricks} - {Pyro} {Tutorials} 1.8.1 documentation},
	url = {https://pyro.ai/examples/svi_part_iv.html},
	urldate = {2022-06-27},
}

@article{bauer_quiet_2015,
	title = {The quiet revolution of numerical weather prediction},
	volume = {525},
	issn = {0028-0836, 1476-4687},
	url = {http://www.nature.com/articles/nature14956},
	doi = {10.1038/nature14956},
	language = {en},
	number = {7567},
	urldate = {2022-07-01},
	journal = {Nature},
	author = {Bauer, Peter and Thorpe, Alan and Brunet, Gilbert},
	month = sep,
	year = {2015},
	pages = {47--55},
	file = {Bauer et al. - 2015 - The quiet revolution of numerical weather predicti.pdf:/home/harnist/Zotero/storage/9I8FYVJ4/Bauer et al. - 2015 - The quiet revolution of numerical weather predicti.pdf:application/pdf},
}

@article{rinehart_three-dimensional_1978,
	title = {Three-dimensional storm motion detection by conventional weather radar},
	volume = {273},
	copyright = {1978 Nature Publishing Group},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/273287a0},
	doi = {10.1038/273287a0},
	abstract = {KNOWLEDGE of the kinematic structure of storms is important for understanding the internal physical processes. Radar has long provided information on the three-dimensional structure of storms from measurements of the radar reflectivity factor alone. Early users of radar gave total storm movement only, whereas later radar data were used to reveal internal motions based on information related to cloud physics such as the three-dimensional morphology of the storm volume. Such approaches have continued by using the increasingly finer scale details provided by more modern radar systems. Both Barge and Bergwall2 and Browning and Foote3 have used fine scale reflectivity structure to determine airflow in hailstorms. Doppler radar added a new dimension to our capabilities through its ability to measure directly the radial component of motion of an ensemble of hydrometeor particles. Two4 or three5 Doppler radars collecting data in conjunction, the equation of mass continuity, and an empirical radar reflectivity–terminal velocity relationship have enabled the estimation of the full three-dimensional airflow fields in parts of storms. Because of the inherent advantage of Doppler radar in motion detection, little effort has been directed toward developing objective schemes of determining internal storm motions with conventional meteorological radars. Pattern recognition schemes using correlation coefficient techniques6, Fourier analysis7, and gaussian curve fitting8 have been used with radar and satellite data, but primarily for detecting overall storm motions, echo merging and echo splitting. Here we describe an objective use of radar reflectivity factor data from a single conventional weather radar to give information related to the three-dimensional motions within a storm.},
	language = {en},
	number = {5660},
	urldate = {2022-07-01},
	journal = {Nature},
	author = {Rinehart, R. E. and Garvey, E. T.},
	month = may,
	year = {1978},
	note = {Number: 5660
Publisher: Nature Publishing Group},
	keywords = {Humanities and Social Sciences, multidisciplinary, Science},
	pages = {287--289},
	file = {Snapshot:/home/harnist/Zotero/storage/76NZ2XTD/273287a0.html:text/html},
}

@misc{shi_deep_2017,
	title = {Deep {Learning} for {Precipitation} {Nowcasting}: {A} {Benchmark} and {A} {New} {Model}},
	shorttitle = {Deep {Learning} for {Precipitation} {Nowcasting}},
	url = {http://arxiv.org/abs/1706.03458},
	abstract = {With the goal of making high-resolution forecasts of regional rainfall, precipitation nowcasting has become an important and fundamental technology underlying various public services ranging from rainstorm warnings to ﬂight safety. Recently, the Convolutional LSTM (ConvLSTM) model has been shown to outperform traditional optical ﬂow based methods for precipitation nowcasting, suggesting that deep learning models have a huge potential for solving the problem. However, the convolutional recurrence structure in ConvLSTM-based models is location-invariant while natural motion and transformation (e.g., rotation) are location-variant in general. Furthermore, since deep-learning-based precipitation nowcasting is a newly emerging area, clear evaluation protocols have not yet been established. To address these problems, we propose both a new model and a benchmark for precipitation nowcasting. Speciﬁcally, we go beyond ConvLSTM and propose the Trajectory GRU (TrajGRU) model that can actively learn the location-variant structure for recurrent connections. Besides, we provide a benchmark that includes a real-world large-scale dataset from the Hong Kong Observatory, a new training loss, and a comprehensive evaluation protocol to facilitate future research and gauge the state of the art.},
	language = {en},
	urldate = {2022-07-01},
	publisher = {arXiv},
	author = {Shi, Xingjian and Gao, Zhihan and Lausen, Leonard and Wang, Hao and Yeung, Dit-Yan and Wong, Wai-kin and Woo, Wang-chun},
	month = oct,
	year = {2017},
	note = {arXiv:1706.03458 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {Shi et al. - 2017 - Deep Learning for Precipitation Nowcasting A Benc.pdf:/home/harnist/Zotero/storage/2QTNGF3E/Shi et al. - 2017 - Deep Learning for Precipitation Nowcasting A Benc.pdf:application/pdf},
}

@misc{shi_convolutional_2015,
	title = {Convolutional {LSTM} {Network}: {A} {Machine} {Learning} {Approach} for {Precipitation} {Nowcasting}},
	shorttitle = {Convolutional {LSTM} {Network}},
	url = {http://arxiv.org/abs/1506.04214},
	doi = {10.48550/arXiv.1506.04214},
	abstract = {The goal of precipitation nowcasting is to predict the future rainfall intensity in a local region over a relatively short period of time. Very few previous studies have examined this crucial and challenging weather forecasting problem from the machine learning perspective. In this paper, we formulate precipitation nowcasting as a spatiotemporal sequence forecasting problem in which both the input and the prediction target are spatiotemporal sequences. By extending the fully connected LSTM (FC-LSTM) to have convolutional structures in both the input-to-state and state-to-state transitions, we propose the convolutional LSTM (ConvLSTM) and use it to build an end-to-end trainable model for the precipitation nowcasting problem. Experiments show that our ConvLSTM network captures spatiotemporal correlations better and consistently outperforms FC-LSTM and the state-of-the-art operational ROVER algorithm for precipitation nowcasting.},
	urldate = {2022-07-01},
	publisher = {arXiv},
	author = {Shi, Xingjian and Chen, Zhourong and Wang, Hao and Yeung, Dit-Yan and Wong, Wai-kin and Woo, Wang-chun},
	month = sep,
	year = {2015},
	note = {arXiv:1506.04214 [cs]
version: 2},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:/home/harnist/Zotero/storage/V6YZ7Z9M/Shi et al. - 2015 - Convolutional LSTM Network A Machine Learning App.pdf:application/pdf;arXiv.org Snapshot:/home/harnist/Zotero/storage/QEKUKQR4/1506.html:text/html},
}

@article{seed_formulation_2013,
	title = {Formulation and evaluation of a scale decomposition-based stochastic precipitation nowcast scheme},
	volume = {49},
	issn = {1944-7973},
	url = {http://onlinelibrary.wiley.com/doi/abs/10.1002/wrcr.20536},
	doi = {10.1002/wrcr.20536},
	abstract = {There are significant uncertainties inherent in precipitation forecasts and these uncertainties can be communicated to users via large ensembles that are generated using stochastic models of forecast error. The Met Office and the Australian Bureau of Meteorology developed the Short Term Ensemble Prediction System (STEPS) was developed to address these user requirements and has been operational for a number of years. The initial formulation of Bowler et al. (2006) has been revised and extended to improve the performance over large domains, to include radar observation errors, and to facilitate the combination of forecasts from a number of sources. This paper reviews the formulation of STEPS, discusses those aspects of the formulation that have proved most problematic and presents some solutions. The performance of STEPS nowcasts is evaluated using a combination of case study examples and statistical verification from the UK. Routine forecast verification demonstrates that STEPS is capable of producing near optimal blends of a rainfall nowcast and high resolution NWP forecast. It also shows that the spread of STEPS nowcast ensembles are a good predictor of the error in the control member (unperturbed) nowcast.},
	language = {en},
	number = {10},
	urldate = {2022-07-02},
	journal = {Water Resources Research},
	author = {Seed, Alan W. and Pierce, Clive E. and Norman, Katie},
	year = {2013},
	note = {\_eprint: https://agupubs.onlinelibrary.wiley.com/doi/pdf/10.1002/wrcr.20536},
	keywords = {rainfall, nowcast, uncertainty},
	pages = {6624--6641},
	file = {Full Text PDF:/home/harnist/Zotero/storage/I5G57QTA/Seed et al. - 2013 - Formulation and evaluation of a scale decompositio.pdf:application/pdf;Snapshot:/home/harnist/Zotero/storage/BCBZN6Q7/wrcr.html:text/html},
}

@article{leinonen_climatology_2012,
	title = {A {Climatology} of {Disdrometer} {Measurements} of {Rainfall} in {Finland} over {Five} {Years} with {Implications} for {Global} {Radar} {Observations}},
	copyright = {info:eu-repo/semantics/openAccess},
	url = {https://helda.helsinki.fi/handle/10138/36973},
	abstract = {To improve the understanding of high-latitude rain microphysics and its implications for the remote sensing of rainfall by ground-based and spaceborne radars, raindrop size measurements have been analyzed that were collected over five years with a Joss–Waldvogel disdrometer located in Järvenpää, Finland. The analysis shows that the regional climate is characterized by light rain and small drop size with narrow size distributions and that the mutual relations of drop size distribution parameters differ from those reported at lower latitudes. Radar parameters computed from the distributions demonstrate that the high latitudes are a challenging target for weather radar observations, particularly those employing polarimetric and dual-frequency techniques. Nevertheless, the findings imply that polarimetric ground radars can produce reliable “ground truth” estimates for space observations and identify dual-frequency radars utilizing a W-band channel as promising tools for observing rainfall in the high-latitude climate.},
	language = {eng},
	urldate = {2022-07-02},
	author = {Leinonen, Jussi and Moisseev, Dmitri and Leskinen, Matti and Petersen, Walter A.},
	year = {2012},
	note = {Accepted: 2012-09-30T22:50:46Z},
	file = {Full Text PDF:/home/harnist/Zotero/storage/85NA85GV/Leinonen et al. - 2012 - A Climatology of Disdrometer Measurements of Rainf.pdf:application/pdf;Snapshot:/home/harnist/Zotero/storage/HG32YS5G/36973.html:text/html},
}

@book{fabry_radar_2018,
	title = {Radar {Meteorology}: {Principles} and {Practice}},
	isbn = {978-1-316-29947-0},
	shorttitle = {Radar {Meteorology}},
	abstract = {This practical textbook introduces the fundamental physics behind radar measurements, to guide students and practitioners in the proper interpretation of radar reflectivity, Doppler velocity and dual-polarization imagery. Operational applications are explored, such as how radar imagery can be used to analyze and forecast convective and widespread weather systems. The book concludes with an overview of current research topics, including the study of clouds and precipitation using radars, signal processing, and data assimilation. Numerous full-color illustrations are included, as well as problem sets, case studies, and a variety of supplementary electronic material including animated time sequences of images to help convey complex concepts. This book is a valuable resource for advanced undergraduate and graduate students in radar meteorology and other related courses, such as precipitation microphysics and dynamics. It will also make a useful reference for researchers, professional meteorologists and hydrologists.},
	language = {en},
	publisher = {Cambridge University Press},
	author = {Fabry, Frédéric},
	month = mar,
	year = {2018},
	note = {Google-Books-ID: 0aRwCQAAQBAJ},
	keywords = {Science / Earth Sciences / Hydrology, Science / Earth Sciences / Meteorology \& Climatology, Science / Physics / General},
}

@misc{noauthor_next_2020,
	title = {Next {Generation} {Weather} {Radar} ({NEXRAD})},
	url = {http://www.ncei.noaa.gov/products/radar/next-generation-weather-radar},
	abstract = {The Next Generation Weather Radar (NEXRAD) system is a network of 160 high-resolution S-band Doppler weather radars jointly operated by the National Weather Service (NWS), the Federal Aviation Administration (FAA), and the U.S. Air Force. The NEXRAD system detects precipitation and wind, and its data can be processed to map precipitation patterns and movement. NCEI provides access to archived NEXRAD Level-II data and Level-III products.},
	language = {en},
	urldate = {2022-07-02},
	journal = {National Centers for Environmental Information (NCEI)},
	month = sep,
	year = {2020},
}

@article{saltikoff_opera_2019,
	title = {{OPERA} the {Radar} {Project}},
	volume = {10},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2073-4433},
	url = {https://www.mdpi.com/2073-4433/10/6/320},
	doi = {10.3390/atmos10060320},
	abstract = {The Operational Program on the Exchange of Weather Radar Information (OPERA) has co-ordinated radar co-operation among national weather services in Europe for more than 20 years. It has introduced its own, manufacturer-independent data model, runs its own data center, and produces Pan-European radar composites. The applications using this data vary from data assimilation to flood warnings and the monitoring of animal migration. It has used several approaches to provide a homogeneous combination of disparate raw data and to indicate the reliability of its products. In particular, if a pixel shows no precipitation, it is important to know if that pixel is dry or if the measurement was missing.},
	language = {en},
	number = {6},
	urldate = {2022-07-02},
	journal = {Atmosphere},
	author = {Saltikoff, Elena and Haase, Günther and Delobbe, Laurent and Gaussiat, Nicolas and Martet, Maud and Idziorek, Daniel and Leijnse, Hidde and Novák, Petr and Lukach, Maryna and Stephan, Klaus},
	month = jun,
	year = {2019},
	note = {Number: 6
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {precipitation, international co-operation, quality control, weather radars},
	pages = {320},
	file = {Full Text PDF:/home/harnist/Zotero/storage/V62FU7AA/Saltikoff et al. - 2019 - OPERA the Radar Project.pdf:application/pdf;Snapshot:/home/harnist/Zotero/storage/YNCTD8AN/htm.html:text/html},
}

@inproceedings{cao_measurement_2016,
	title = {Measurement uncertainty and system assessment of weather radar network in {Germany}},
	doi = {10.1109/RADAR.2016.7485284},
	abstract = {The Deutscher Wetterdienst (D WD) weather radar network has been upgraded with new C-band Polarimetrie radar systems. The current study presents the results of a field research campaign, which was designed to assess the radar systems through analyzing radar measurements. A novel point mode approach proposed recently by Enterprise Electronics Corporation (EEC) was used for the data collection and analysis. Results show that DWD weather radars generally have a high system quality and contribute a negligible uncertainty to the radar measurements, as compared to the uncertainty caused by the sampling effect. The proposed point mode approach is validated with DWD radar data analysis and highly recommended as quality measure for commercial weather radars.},
	booktitle = {2016 {IEEE} {Radar} {Conference} ({RadarConf})},
	author = {Cao, Qing and Knight, Michael and Frech, Michael and Mammen, Theodor},
	month = may,
	year = {2016},
	note = {ISSN: 2375-5318},
	keywords = {Measurement errors, Meteorological radar, Meteorology, polarimetric weather radar, Radar antennas, Radar measurements, Radar polarimetry, system assessment},
	pages = {1--5},
	file = {IEEE Xplore Abstract Record:/home/harnist/Zotero/storage/T79R7N87/7485284.html:text/html;IEEE Xplore Full Text PDF:/home/harnist/Zotero/storage/ZKEAFQ3M/Cao et al. - 2016 - Measurement uncertainty and system assessment of w.pdf:application/pdf},
}

@article{kiureghian_aleatory_2009,
	series = {Risk {Acceptance} and {Risk} {Communication}},
	title = {Aleatory or epistemic? {Does} it matter?},
	volume = {31},
	issn = {0167-4730},
	shorttitle = {Aleatory or epistemic?},
	url = {https://www.sciencedirect.com/science/article/pii/S0167473008000556},
	doi = {10.1016/j.strusafe.2008.06.020},
	abstract = {The sources and characters of uncertainties in engineering modeling for risk and reliability analyses are discussed. While many sources of uncertainty may exist, they are generally categorized as either aleatory or epistemic. Uncertainties are characterized as epistemic, if the modeler sees a possibility to reduce them by gathering more data or by refining models. Uncertainties are categorized as aleatory if the modeler does not foresee the possibility of reducing them. From a pragmatic standpoint, it is useful to thus categorize the uncertainties within a model, since it then becomes clear as to which uncertainties have the potential of being reduced. More importantly, epistemic uncertainties may introduce dependence among random events, which may not be properly noted if the character of uncertainties is not correctly modeled. Influences of the two types of uncertainties in reliability assessment, codified design, performance-based engineering and risk-based decision-making are discussed. Two simple examples demonstrate the influence of statistical dependence arising from epistemic uncertainties on systems and time-variant reliability problems.},
	language = {en},
	number = {2},
	urldate = {2022-07-04},
	journal = {Structural Safety},
	author = {Kiureghian, Armen Der and Ditlevsen, Ove},
	month = mar,
	year = {2009},
	keywords = {Aleatory, Epistemic, Ergodicity, Parameter uncertainty, Predictive models, Probability distribution choice, Statistical dependence, Systems, Time-variant reliability, Uncertainty},
	pages = {105--112},
	file = {ScienceDirect Full Text PDF:/home/harnist/Zotero/storage/3DKGS99L/Kiureghian and Ditlevsen - 2009 - Aleatory or epistemic Does it matter.pdf:application/pdf},
}
